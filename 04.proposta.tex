% !TeX root = ./00.main.tex
\chapter{Proposta e metodologia}\label{cha:proposta}

\begin{resumocap}

  Este Capítulo apresenta a proposta deste trabalho e a metodologia elegida para
  atingir os objetivos.

\end{resumocap}

% Uma Implementação paralela do algoritmo de Detecção de Novidade em Streams MINAS 
\newcommand{\fog}{\emph{fog computing}\xspace}
\newcommand{\cloud}{\emph{cloud computing}\xspace}

\newcommand{\mfog}{M-FOG\xspace}
\newcommand{\flink}{\emph{Apache Flink}\xspace}

A Internet das Coisas (\iot) é composta por milhares de dispositivos distribuídos
geograficamente conectados à Internet.
Com capacidades diversas como sensores e atuadores, esses dispositivos produzem e
consomem Fluxos Continuos de Dados (\streams) com diversos objetivos.
Alguns objetivos envolvem a mineração desses fluxos (\streamMining) em busca de
padrões para tomada de decisão e, por vezes requerem também baixa latência.
Para casos de baixa latência ou alta vazão, conexões adequadas para
processamento em nuvem nem sempre são possíveis ou desejáveis, para esses casos
computação em névoa (\fog) é uma solução.

O tema de \streamMining envolve a classificação de novos elementos com base em
um modelo, porém como \streams variam temporalmente e são ilimitados, todas
classes contidas em um \stream não são previamente conhecidas.
A identificação e classificação de novas classes em \streams é denominado
Detecção de Novidades (\novelty, \nd) em \streams.
No tema de \nd, o surgimento e desaparecimento de classes é nomeado Evolução de Conceito
(\evolution) e a mudança no decorrer do \stream é denominado Mudança ou Deriva
de Conceito (\drift).

Além dos aspectos inerentes \streamMining, são considerados na construção de um
sistema que computa \streams a taxa de eventos (itens atômicos de um \stream)
gerados por cada produtor e o número de produtores nesse sistema totalizando o
volume de eventos do sistema.
Volumes elevados são dificilmente computados em apenas um nó e muito menos em um
único núcleo computacional, por esse motivo esses sistemas são distribuídos.

Sistemas que utilizam \nd para \streams gerados por dispositivos \iot devem
utilizar algoritmos que considerem os desafios inerentes de fluxos de dados
(\evolution e \drift) para adequada detecção de novidades e arquiteturas
que atendam os requisitos de volume de mensagens e latência de detecção.
O algoritmo MINAS é adequado pois trata os desafios de \streamMining porém não
tem ainda implementação que atenda os requisitos de volume e latência,
especialmente para aplicações \iot onde um ambiente de \fog é atrativo.

Para preencher a lacuna de algoritmo de \nd em ambiente \fog propõem-se então
\mfog, uma implementação do algoritmo MINAS sobre a plataforma \flink que
considera distribuição em um ambiente de \fog.

% \nota{Reestruturar:
%   A - remember,
%   B - cenário (iot, fog, stream),
%   C - problema (4.1, ND em fog, terminar com minas e cassales),
%   D - solução (4.2, apresetnação, resumo \mfog, metodologia)
% }
% \nota{Falta: fog, processamento distribuído de streams, detecção de novidade}

\section{Descrição da Implementação}\label{sec:descricao}

\newcommand{\source}{\emph{source}\xspace}
\newcommand{\sink}{\emph{sink}\xspace}

\newcommand{\offline}{treinamento\xspace}
\newcommand{\classify}{classificador\xspace}
\newcommand{\detector}{detector\xspace}

Nesta Seção apresenta-se \mfog, objeto proposta deste trabalho.
O \mfog é composto pelos módulos: \offline, \classify e \detector.
Para correta avaliação, \mfog é acompanhado de dois módulos auxiliares:
módulo fonte (\source) e módulo sorvedouro (\sink).

% \nota{métodos para alcançar os objetivos}

% \nota{o que fazer e como fazer, resultados esperados}

A implementação proposta segue a arquitetura \idsiot formalizada por
\citeonline{Cassales2019a} discutido na \refsec{cassales}.
A arquitetura \idsiot estabelece que um serviço de captura e tratamento de dados
é instalado na borda de uma rede local com dispositivos \iot.
Na presente implementação
esse serviço de captura e tratamento é representado pelo módulo \source.

O módulo auxiliar \source é dependente da fonte de dados, executando a transformação dos
formatos dos \datasets para um fluxo de dados compatível com o restante da
implementação.
Além de fornecer dados tratados para \mfog, o módulo \source também fornece
dados para o módulo \sink e \offline.

O módulo auxiliar \sink é responsável por agregar todos resultados do \mfog e,
juntamente com os valores do \dataset fornecidos pelo módulo \source, computar
as métricas de qualidade de classificação e métricas base para as métricas de
escalabilidade e métricas de recursos computacionais.

Os dados resultantes do serviço de captura e tratamento são ingeridos pela
aplicação no módulo \classify por meio de conexão TCP (\emph{Transmission
Control Protocol}) fornecida pela plataforma \flink.
Na plataforma, com o modelo de classificação disponível, os exemplos são
classificados seguindo o algoritmo MINAS original discutido na \refsec{minas-og}.
A etiqueta atribuída pela classificação, ou meta-etiqueta de desconhecido,
juntamente com o exemplo original são enviados para o módulo \sink.
Além disso, se o exemplo não for classificado, o mesmo é enviado para o módulo
\detector.

O módulo \detector é responsável por executar o processo de detecção de
novidade, atualizando o modelo de classificação, e entrega do novo modelo
ao módulo \classify.
Este módulo também envia meta-informações sobre o processo de detecção de
novidade para o módulo \sink.

\nota{citar ferramentas e a escolha só depois do python e kafka}

\nota{entre flink e spark, outro grupo de pesquisa já está explorando spark}

\section{Metodologia de Avaliação e Resultados Esperados}\label{sec:esperados}

% \nota{reestrutura 2:
%   A - cenario
%   B - metodologia (como, o que vai implementar [kafka, python, flink], como avaliar)
%   C - métricas (escalabilidade, qualidade)
%   D - resultados preliminares (python/kafka, flink)
% }

A avaliação da proposta apresentada será feita por meio de métricas extraídas da
literatura, divididas em duas partes: métricas de qualidade de classificação
e métricas de escalabilidade.

Métricas tradicionais de qualidade de classificação estabelecidas por trabalhos
aprendizado de máquina não são adequadas para avaliar detecção de novidades em
\streams sem tratamento inicial, felizmente o tratamento necessário é
estabelecido por \citeonline{Faria2013} e expandido por
\citeonline{DaSilva2018,DaSilva2018thesis,Costa2019,Costa2019thesis}.
O tratamento estabelece que as métricas são extraídas de uma matriz de erro de
classificação multi-classe \ref{eq:matrix} adaptada para detecção de novidade.
A matriz é preenchida com o número de eventos da classe $c_i$ classificados com
etiqueta $l_j$ até o instante $n$.
A equação \ref{eq:classes} representa o conjunto de classes presentes nos eventos
do fluxo até o instante $n$ e a equação \ref{eq:labels} representa o conjunto
de etiquetas atribuídas pelo classificador à eventos até o mesmo instante.

\begin{align}
  % x_n &= classify_{n-1}(x_n)\\
  % e_{i, j} &= classify_{n-1}(x_n)\\
  \mathbf{C}_n &= \{ c_1, c_2, \cdots, c_M \}  \label{eq:classes} \\
  \mathbf{L}_n &= \{ l_1, l_2, \cdots, l_J \}  \label{eq:labels} \\
  \mathbf{E}_n &= \begin{pmatrix}
    e_{1,1} & e_{1,2} & \cdots & e_{1,J} \\
    e_{2,1} & e_{2,2} & \cdots & e_{2,J} \\
    \vdots  & \vdots  & \ddots & \vdots  \\
    e_{M,1} & e_{M,2} & \cdots & e_{M,J} 
  \end{pmatrix}  \label{eq:matrix}
\end{align}

As métricas selecionadas são taxa de desconhecidos ($UnkR$) \cite{Faria2013},
acurácia média ($acc$) e Macro F-score ($Fscore$, F1M)
\cite{Sokolova2009,DaSilva2018thesis}.

% e \emph{Logarithm Loss} ($\mathcal{L}$).

%   \mathbf{C} &= [c_1, c_2, \cdots, c_I] \\
%   \mathbf{L} &= [l_1, l_2, \cdots, l_J] \\
%   \forall n\to\infty: & \\
%   \mathbf{C}_{n}  &= \mathbf{C}_{n-1} \cup c \in \mathbf{C} \\
%   \mathbf{L}_{n}  &= \mathbf{L}_{n-1} \cup l \in \mathbf{L} \\
%   X               &= (n, \overrightarrow{x}, c) \\
%   Y = \mathrm{classifica}(X) &= (n, \overrightarrow{x}, l \vee \text{unk}) \\
%   \mathbf{Unk}    &= \{ Y : (_, _, l = \text{unk}) \} \\
% \mathit{UnkR}_n   &= \frac{ \#Unk }{n}

\begin{align}
  \mathit{UnkR}       &= \frac{1}{M} \sum_{i=1}^{M} \frac{\#Unk_i}{\#ExC_i}\\
  \mathit{acc}        &= \frac{1}{M} \sum_{i=1}^{M} \frac{tp_i + tn_i}{tp_i+fn_i+fp_i+tn_i}
  = \frac{1}{M} \sum_{i=1}^{M} \frac{\#Acc_i}{\#ExC_i}\\
  \mathit{Precision}  &= \frac{1}{M} \sum_{i=1}^{M} \frac{tp_i}{tp_i+fp_i} \\
  \mathit{Recall}     &= \frac{1}{M} \sum_{i=1}^{M} \frac{tp_i}{tp_i+fn_i} \\
  \mathit{Fscore}_\beta &= (\beta^2 +1) \cdot
  \frac{
  \mathit{Precision} \cdot \mathit{Recall}
  }{
    \beta^2 \cdot \mathit{Precision} +\mathit{Recall}
  }\\
  \mathit{Fscore}_1   &= 2 \cdot \frac{
    \mathit{Precision} \cdot \mathit{Recall}
    }{
      \mathit{Precision} +\mathit{Recall}
    } 
\end{align}
% = 2 \cdot \frac{tp}{2 \cdot tp + fn + fp}
% \mathcal{L}         &= \frac{-1}{N} \sum_{i=1}^{M} \sum_{j=1}^{J} y_{i,j} \log(p_{i,j})



\nota{usar coeficiente d-intra vs d-extra grupo para determinar K de
cada label}

O tratamento do fluxo de saída é realizado no módulo \sink onde tem-se
disponível o fluxo original com as etiquetas corretas.
Esse módulo deve levar em consideração que
como pode haver reclassificação de um evento, previamente rotulado como
desconhecido, em padrões oriundos de classe novidade ou extensão devido ao
processo de detecção de novidades executado posteriormente ao surgimento
do padrão em questão.
Portanto os resultados são computados em função do fluxo de saída, então $n$ nas
equações são o índice do evento de saída.
$\mathbf{unk}$ é o conjunto de eventos marcados como desconhecidos.

% \begin{align}
%   E_{n,i,j} &= \bordermatrix{~ & c_i & \neg c_i \cr
%   l_j       & TP = \alpha           & FP = \gamma - \alpha                 \cr
%   \neg l_j  & FN = \beta - \alpha   & TN = n - (\alpha + \beta + \gamma)  \cr} \\
%   FM1       &= \frac{TP}{TP+\frac{FP+FN}{2}}
% \end{align}

% Os valores da matriz de erro para 

% \begin{align}
%   \alpha _j &= max( \{ |e_{i,j}|: i = 1 .. I \wedge \in \mathbf{E}_n \})
%           & \text{máximo da linha (etiqueta)} \\
%   a_j &= i: |e_{i,j}| = \alpha _j
%           & \text{índice da classe associada à etiqueta} \\
%   \beta   &= \sum_{j = 0}^{J} e_{i,j} : e_{i,j} \in \mathbf{E}_n
%           & \text{soma de uma coluna (etiqueta)} \\
%   \gamma  &= \sum_{i = 0}^{I} a_{i,j} : e_{i,j} \in \mathbf{E}_n
%           & \text{soma de uma linha (classe)}
% \end{align}

As métricas de escalabilidade selecionadas são número de nós processadores, tipo
de processadores, uso de memória, tempo de processamento, taxa de eventos
processados e latência entre a produção e classificação de um evento.

Da implementação \mfog é prevista execução de experimentos com \datasets
diversos, em especial os \datasets reais que contém evolução de conceitos.
Os resultados desses experimentos são válidos se contém as seguintes métricas
para o \mfog: \begin{enumerate*}[label={\alph*)}]
  \item qualidade de classificação (taxa de desconhecidos, F1M)
  \item escalabilidade (número de processadores, volume processado, tempo decorrido)
  \item recursos computacionais utilizados (memória, tempo de processamento, operações de leitura e escrita)
\end{enumerate*}
e para o minas somente as métricas de qualidade de classificação.

\section{Resultados preliminares}\label{sec:resultados}

\nota{introdução dizendo que já foi caminhada/explorada uma parte}

\newcommand{\kafka}{\emph{Apache Kafka}\xspace}
\newcommand{\python}{\emph{Python}\xspace}

\subsection{Implementação com \python e \kafka}

A primeira implementação e avaliação do \mfog realizada foi construída sobre a
linguagem \python com o sistema de fila de mensagens \kafka e a respectiva
biblioteca de conexão.
A escolha desse conjunto para a implementação deu-se devido a ampla
disponibilidade de bibliotecas de aprendizagem de máquina no ecossistema
\python e simplicidade geral da linguagem.
O sistema \kafka recebe mensagens e as armazena em tópicos distribuídos em
partições replicadas em nós de um \cluster, gerenciados por um nó mestre e
suportado pelo serviço de gerenciamento de configuração distribuída \emph{Apache
ZooKeeper}.
A aplicação python consome eventos através da biblioteca \emph{Consumer API}
que expõem a distribuição através da associação de um consumidor às partições
mantidas pelo \kafka.

No entanto, a hipótese de que a distribuição de mensagens gerenciada pelo \kafka
se estenderia às processos consumidores, efetivamente distribuindo o volume de
mensagens entre eles igualmente, não se realizou nos experimentos realizados.
Os experimentos em questão foram compostos de 8 processos consumidores, 1
processo produtor, 1 instância \kafka com 8 partições em seu tópico principal
e uma instância \emph{Apache ZooKeeper} associada à instancia \kafka.

A hipótese era que como o número de partições igualava o número de produtores e
cada produtor associaria-se a uma partição.
No entanto essa hipótese foi refutada quando observou-se que o número de
mensagens consumidas por um dos 8 processos representava a maioria (mais de
80\%) do volume introduzido no sistema, o restante sendo distribuído entre
outros 3 processos e o restante dos processos não recebia nenhuma mensagem.

Portanto iniciativa de implementar o algoritmo MINAS em \python com \kafka e
atingir os objetivos de distribuição falhou, o que levou a reconsideração das
plataformas escolhidas.

\subsection{Implementação com \flink}

A segunda alternativa explorada teve por inspiração o trabalho de
\citeonline{Viegas2019}

% \chapter{Resultados Preliminares: implementação e testes}\label{cha:imp}
% cap 4: Implementação e testes
%     4.1. descrição da implementação
%         - offline, online, ND, Clustering
%         - observação de paralelização
%         - complexidade bigO (?)
%     4.2. cenário de teste 
%         - detecção de intrusão
%         - Arquitetura guilherme (dispositivos pequenos vs cloud)
%     4.3. Resultados de experimentos
%         - gráficos, tempos, tabelas...
%         - análises e comentários

% \begin{resumocap}
% \end{resumocap}

\nota{Esse trabalho propos-se a fazer}

% % hélio
% notas sobre a distribuição do modelo
% - cenário com o processamento de novidades local
% - cenário com ND na nuvem

% - minas totalmente active

% helio amanha:
% a. Cenário, b. Problema, c. Proposta e d. Resultado Esperado.
% hermes:
% a. Monitoramento, classificação,
% b. detecção de novidades,
% c. executar em nós multi-core de maneira escalável,
% d. minas com mesma qualidade porém escalável.

% helio:
% Técnicas de firewall tradicional: allow all, deny all.
% Firewall moderno usa modelos.
% Minas como modelo.

% hermes
% iot, nós expostos vitima de ataque, novas funcionalidades ->
% firewall rigido vs modelos -> streams ->
% novidade -> minas -> big data -> discussão de localidade de dados
% paralelização

% motivação: testes preliminares do guilherme que fez teste com tais bases
% teve resultados promissores

% - implementar
% - paralelizar
% - avaliar
% - avaliar aprendizado local ou global trade-offs


% % luis
% O minas abre espaço 

% % hermes
% escalabilidade do algoritmo

% Kafka particiona e expoem esse particionamento ao consumidor.
% Tentei usar Python + Kafka, mas não escalou.

% Detalhar a implementação

% % hermes, esqueça kafka, foque em arquivos


% \section{Descrição da Implementação}
% \section{Objetivos a serem alcançados}
% O que de fato vc irá fazer 

\nota{
- offline, online, ND, Clustering \\
- observação/Considerações de paralelização \\
- Notas sobre implementação Python/Kafka/Minas (não escala como esperado) \\
- Dificuldade no processamento distribuido em Flink. \\
- complexidade bigO (?)
}

\subsection{Ambiente de Teste}

Para testar e demonstrar essa implementação um cenário de aplicação é construído
onde seria vantajoso distribuir o processamento segundo o modelo \emph{fog}. Alguns
cenários de exemplo são
casos onde deve-se tomar ação caso uma classe ou anomalia seja detectada


% In time, process control and automation of industrial facilities, ranging from
% oil refineries to corn flakes factories \cite{Stonebraker2005}

% dataset kyoto não está disponível {http://www.takakura.com/Kyoto_data/}

\nota{- detecção de intrusão\\
- Arquitetura guilherme (dispositivos pequenos vs cloud)\\
- Descrever a arquitetura IDS-IoT do paper do Guilherme \ cite{Cassales2019a}\\
- dataset kyoto não está disponível\\
- \ dataset kdd99\\
- BigFlow com \ dataset atual e maior
}

% \subsection{Experimentos e Resultados}

\nota{
- gráficos, tempos, tabelas...\\
- análises e comentários\\
- Mostrar alguma implementação já feita e que esteja funcionando minimamente
}

\nota{Mostrar resultados mesmo que sejam bem simples e básicos,
apenas para demonstrar que vc domina o ambiente e as ferramentas e
que está apto a avançar no trabalho}

\nota{discussão de 2020-02-01:\\
passos feitos/a fazer\\
1. Entender Minas\\
2. Analisar/descrever data set KDD\\
3. Notas sobre implementação Python/Kafka/Minas (não escala como esperado)\\
4. BigFlow (data set mais novo, usa flink)\\
5. Plataforma Flink (processamento distribuído)\\
Proposta\\
6. Implementar minas em Scala/Flink\\
7. Testar com data sets KDD e BigFlow\\
8. Validar/Comparar métricas com seus trabalhos correspondentes
}

\nota{lendo Quali Casssales:\\
- Descrição do hardware utilizado pode conter:\\
    - Arch, OS, Kernel,\\
    - CPU (core, thread, freq),\\
    - RAM (total/free size, freq),\\
    - Disk (total/free size, seq RW, rand RW),\\
    - Net IO between nodes (direct crossover, switched, wireless, to cloud) (bandwidth, latency).\\
essas métricas permitem relacionar trade-offs para as questões de fog: Processar em node, edge ou cloud?
}

\nota{Provavelmente vou retirar o kafka da jogada em node/edge, deixando apenas em cloud.}
