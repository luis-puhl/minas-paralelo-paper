\chapter{Introdução}

% Se

% ELEMENTOS QUE INTRO DEVE TER
% -contexto
% - problema
% - sua solucao
% - como vc vai fazer (metodologia/simples)
% - pq é importante (justificativa)
% - ja teve algum resultado preliminar (se sim, cita ele)
% - organizacao do trabalho( no capitulo 1 teremos... no capitulo 2 teremos ...)

% ------------------------------------------------------------------------------------------------------
% % hélio
% notas sobre a distribuição do modelo
% - cenário com o processamento de novidades local
% - cenário com ND na núvem

% - minas totalmente active

% helio amanha:
% a. Cenário, b. Problema, c. Proposta e d. Resultado Esperado.
% hermes:
% a. Monitoramento, classificação,
% b. detecção de novidades,
% c. executar em nós multi-core de maneira escalável,
% d. minas com mesma qualidade porém escalável.

% helio:
% Técnicas de firewall tradicional: allow all, deny all.
% Firewall moderno usa modelos.
% Minas como modelo.

% hermes
% iot, nós expostos vitima de ataque, novas funcionalidades ->
% firewall rigido vs modelos -> streams ->
% novidade -> minas -> big data -> discussão de localidade de dados
% paralelização

% motivação: testes preliminares do guilherme que fez teste com tais bases
% teve resultados promissores

% - implementar
% - paralelizar
% - avaliar
% - avaliar aprendizado local ou global trade-offs

% % luis
% O minas abre espaço para diferentes estratégias de paralelismo e distribuição.

% % hermes
% escalabilidade do algoritmo

% Kafka particiona e expõem esse particionamento ao consumidor.
% Tentei usar Python + Kafka, mas não escalou.

% Detalhar a implementação

% % hermes, esqueça kafka, foque em arquivos
% ------------------------------------------------------------------------------------------------------

% Hermes 2020-02-04
% Paralelize o minas no flink.
% (não se preocupe com o uso, seja ele NIDS ou qualquer outra coisa)
% Use a detecção de intrusão apenas como validação do algoritmo.

% cenário 2: NIDS é meu foco, esses são os desafios de NIDS, o minas resolve. mas esse cenário é tragico
% ------------------------------------------------------------------------------------------------------

% cap 1:
%   - Objetivo paralelizar minas em plataforma de big-data capaz de consumir streams de forma eficiente
%   - Motivação: Minas é recente, com potencial em várias aplicações, por exemplo (NIDS, sensores, ...)
%       para isso deseja-se uma implementação eficiente (low power, ou usar todo hardware) e escalável (big-data)
%/hermes
% ------------------------------------------------------------------------------------------------------

% a. Cenário: Monitoramento, classificação,
% b. Problema: detecção de novidades,
% c. Proposta: executar em nós multi-core de maneira escalável,
% d. Resultado Esperado: minas com mesma qualidade porém escalável.
% 
% Linha de argumentação: iot, nós expostos vitima de ataque, novas funcionalidades ->
% firewall rigido vs modelos -> streams -> novidade -> minas ->
% big data -> discussão de localidade de dados e paralelização
% 
% motivação: testes preliminares do guilherme que fez teste com tais bases
% teve resultados promissores
% - implementar
% - paralelizar
% - avaliar
% - avaliar aprendizado local ou global trade-offs

% 3 ou 4 linhas max, quebrar em sentenças
% muito Essa, Esse em começo de parágrafo

A Internet das Coisas (\emph{Internet of Things} - IoT) é um tema frequentemente
abordado na última década claramente motivado crescimento sem precedentes do
número de dispositivos dessa categoria e respectivos dados gerados que podem
trazer novos conhecimentos através da análise desses dados. No entanto, além dos
dados de sensores e atuadores esses dispositivos, quando subvertidos, podem
gerar outro tipo de tráfego, maligno à sociedade, como o gerado pela
\emph{botnet} mirai em 2016 \cite{Kambourakis2017}. Nesse cenário são fatores
que possibilitaram esses ataques: falta de controle sobre a origem do hardware e
software embarcado nos dispositivos além das cruciais atualizações de segurança.

Com milhares de dispositivos em redes distantes gerando dados (diretamente
ligados a sua função original e também metadados produzidos como subproduto) com
volume e velocidade consideráveis formando fluxos contínuos de dados (\emph{Data
Stream} - DS) , técnicas de mineração de fluxos de dados
(\emph{Data Stream Mining}) são amplamente necessárias. Essas técnicas são
aplicadas, por exemplo, em problemas de monitoramento e classificação de valores
originários de sensores para tomada de decisão tanto em nível micro, como
modificação de atuadores remotos, ou macro, na otimização de processos
industriais. Analogamente, as mesmas técnicas podem ser aplicadas para os
metadados gerados pela comunicação entre esses nós e a Internet num serviço de
detecção de intrusão.

Técnicas de \emph{Data Stream Mining} envolvem mineração de dados
(\emph{Data Mining}), aprendizado de
máquina (\emph{Machine Learning}) e recentemente Detecção de Novidades
(\emph{Novelty Detection} - ND). ND além de classificar em modelos conhecidos
permite descobrir novos padrões e, consequentemente, atuar coerentemente mesmo
em face a valores nunca vistos. Essa capacidade é relevante em especial para o
exemplo de detecção de intrusão, onde novidades na rede podem distinguir novas
funcionalidades (entregues aos dispositivos após sua implantação em campo) de
ataques por agentes externos sem assinatura existente em bancos de
dados de ataques conhecidos.

% finalizo com "por exemplo"?

Análises como \emph{Data Stream Mining} e ND são tradicionalmente implementadas
sobre o paradigma de computação na nuvem
(\emph{Cloud Computing}) e, recentemente, paradigmas como computação em névoa
(\emph{Fog Computing}). Para \emph{fog}, além dos recursos em \emph{cloud}, são
explorados os recursos distribuídos pela rede desde o nó remoto até a
\emph{cloud}. Processos que dependem desses recursos são distribuídos de acordo
com características como sensibilidade à latência, privacidade,
consumo computacional ou energético.

\section{Motivação}

No contexto de detecção de novidades para fluxos de dados em \emph{fog}, uma
arquitetura recente proposta por \citeonline{Cassales2019a}, baseada no algoritmo
de detecção de novidades em fluxo de dados MINAS
\cite{Faria2016minas}, mostra resultados promissores.

A arquitetura proposta foi avaliada com conjunto de dados (\emph{dataset}) \emph{Kyoto 2006+} que
coletou dados de 348 \emph{Honeypots} (máquinas isoladas com diversos softwares
com vulnerabilidades conhecidas expostas à Internet com propósito de atrair
ataques) de 2006 até dezembro 2015. Com 24 atributos, 3 etiquetas atribuídas por
detectores de intrusão comerciais de detecção de intrusão e uma etiqueta
distinguindo o tráfego entre normal, ataque conhecido e ataque desconhecido
\cite{Cassales2019a}.
Contudo, esse algoritmo ainda não foi implementado e avaliado com paralelismo
multi-processamento ou distribuído.

Outras propostas tratam do caso de grandes volumes e velocidades, como é o caso
de \citeonline{Viegas2019} que apresenta o \emph{BigFlow} no intuito de detectar
intrusão em redes \emph{10 Gigabit Ethernet}, que é um volume considerável
atualmente impossível de ser processado em um único núcleo de processador
(\emph{single-threaded}). Essa implementação é feita sobre uma plataforma
distribuída processadora de fluxos (\emph{Apache Flink}) executada em um cluster
com até 10 nós de trabalho, cada um com 4 núcleos de processamento totalizando
40 núcleos para atingir taxas de até $10,72 \ Gbps$.

Além de apresentar uma implementação, \citeonline{Viegas2019} também apresenta o
\emph{dataset} \emph{MAWIFlow}. Esse conjunto é derivado do ponto de coleta
F, localizado em um elo de comunicação entre o Japão e os EUA (\emph{Backbone})
com capacidade de $1\ Gbps$, diariamente 15 minutos são capturados desde 2006
sob supervisão de \citeonline{mawiSamplepointF} \cite{Fontugne2010}. O conjunto
\emph{MAWIFlow} limita-se às coletas de 2016 ($7.9\ TB$) e estratificado para
$1\%$ desse tamanho facilitando compartilhamento e avaliação por outros
softwares. Esse conjunto contempla 158 atributos de nós e fluxos e etiquetado
por \citeonline{Fontugne2010}.

O sistema \emph{BigFlow} é composto de dois estágios: extração de
características (estatísticas de tráfego da rede) e aprendizado confiável de
fluxo. O segundo estágio implementa um algoritmo de detecção de novidade
utilizando classificadores já estabelecidos na biblioteca MOA \cite{MOA} com
adição de um módulo de verificação que armazena valores classificados com baixa
confiança para serem manualmente avaliados por um especialista \cite{Viegas2019}.
A escolha dessa
abordagem não é nova e visa mitigar problemas como \emph{Concept Drift} e
\emph{Concept Evolution} \cite{Faria2016nd} com a redução de acurácia durante na
avaliação inicial dos algoritmos tradicionais e devidamente mitigada com a
atualização constante do modelo. Esses problemas são amplamente abordados e
tratados em outros algoritmos como o MINAS \cite{Faria2016minas}.

Os trabalhos de \citeonline{Cassales2019a} e \citeonline{Viegas2019} abordam
detecção de intrusão em redes utilizando algoritmos de ND em DS porém com
perspectivas diferentes.
O primeiro observa \emph{IoT}, processamento em \emph{fog}, baseia-se em um
algoritmo genérico de detecção de novidade e o segundo observa \emph{backbones},
processamento em \emph{cloud}, implementa o próprio algoritmo de detecção de
novidade. Essas diferenças deixam uma lacuna onde de um lado tem-se uma
arquitetura mais adequada para \emph{fog} com um algoritmo estado da arte de
detecção de novidades porém sem paralelismo e de outro tem-se um sistema
escalável de alto desempenho porém almejando outra arquitetura (\emph{cloud}) e
com um algoritmo menos preparado para os desafios de detecção de novidades.

% \textit{
% \\ deixar mais claro o contraste entre cassales e bigflow
% \\ abordar o **gap** no qual a minha pesquisa entra
% \\ mostrar que modelo bigflow não considera fog
% \\ arquiteutra distribuida em fog com minas e alto desempenho big flow
% }

\section{Objetivos}

Com a avaliação inicial formulou-se a questão: Quais resultados podem ser
esperados de um sistema multi-processado que implementa um algoritmo estado da
arte de detecção de novidades em fluxo de dados?

% c. Proposta: executar em nós multi-core de maneira escalável,
% d. Resultado Esperado: minas com mesma qualidade porém escalável.
% 
% Linha de argumentação: discussão de localidade de dados e paralelização
% - implementar
% - paralelizar
% - avaliar
% - avaliar aprendizado local ou global trade-offs

Propõem-se então a construção de uma aplicação que implemente o algoritmo MINAS
de maneira escalável e distribuível para nós \emph{multi-core} e a avaliação
dessa implementação com experimentos baseados na literatura e conjunto de dados
públicos relevantes para facilitar posterior comparação com outras
implementações.

O resultado esperado é uma implementação compatível em qualidade de
classificação à seu original e com escalabilidade semelhante demonstrada pelo
\emph{BigFlow}.

% discussão de 2020-02-01
% nota og: Avaliar o apache flink e o Minas para detecção de intrusão em redes IoT.
% Avaliar o algoritmo minas na plataforma Flink para detecção de intrusão em redes IoT.
% Avaliar = Testes com diferentes datasets (KDD e BigFlow) com as métricas Minas e BigFlow.

% O que o minas-flink tem de especial para detecção de intrusão?
% - conformidade com variação da rede

Com foco no objetivo geral, alguns objetivos secundários são propostos:

% % Objetivos secundários:
% % visto como um passo-a-passo até o objetivo principal.
% Identificar métricas na literatura:
%     - Quanto a detecção de anomalias;
%     - e desempenho na detecção de intrusão da literatura;
% Implementar Minas sobre Apache Flink para detecção de intrusão em redes IoT;
% % Demonstrar que Minas sobre Apache Flink (a implementação) é um alternativa 
% % mudar verbo 'Mostrar' para algo mais concreto/fechado
% Extrair as métricas de detecção de anomalias da implementação com datasets diferentes;
% Validar a implementação comparando as métricas extraídas da implementação com as encontradas na literatura;
% % teste ferramentas de stream (python/kafaka, scala/flink)
% Extrair as métricas de desempenho da implementação com datasets diferentes;

\begin{itemize}
    \item Enumerar métricas de qualidade de classificação e métricas de
    escalabilidade encontradas na literatura;
    \item Avaliar plataformas de processamento distribuído de fluxos como:
    \begin{itemize}
        \item \emph{Apache Kafka} com \emph{Python};
        \item \emph{Apache Kafka Streams};
        \item \emph{Apache Spark Streaming};
        \item \emph{Apache Storm};
        \item \emph{Apache Flink};
    \end{itemize}
    \item Implementar algoritmo MINAS sobre \emph{Apache Flink};
    \item Executar a implementação com \emph{datasets} públicos relevantes;
    \item Validar, por meio de comparação com o algoritmo original, se a
    implementação gera os mesmos resultados quanto a classificação;
    \item Extrair métricas de escalabilidade por meio de experimentação;
    \item Avaliar estratégias de distribuição do algoritmo em \emph{fog} como:
    \begin{itemize}
        \item Detecção de novidade nas pontas;
        \item Detecção de novidade na nuvem;
        \item Detecção de novidade nas pontas e em nuvem;
    \end{itemize}
    e seu o impacto na qualidade de classificação e volume computado.
\end{itemize}

% There is a need for real-time stream processing, as data is arriving as
% continuous flows of events; for example, cars in motion emitting GPS signals;
% financial transactions; the interchange of signals between cellphone towers; web
% traffic including things like session tracking and understanding user behavior
% on websites; and measurements from industrial sensors.
% https://dzone.com/articles/streaming-in-spark-flink-and-kafka-1

\section{Proposta Metodológica}

% (Metodologia) (como)

Os objetivos desse trabalho indicam um processo exploratório e experimental
iniciando com exploração da literatura acadêmica e literatura técnica seguido de
implementação, testes e avaliações experimentais.

O foco da exploração da literatura acadêmica é em trabalhos que abordem
processamento de fluxos de dados, classificação e detecção de novidades nesses
fluxos e distribuição de processamento de fluxo de dados e estabelecimento do
estado da arte desses assuntos. Além disso, nesses trabalhos espera-se encontrar
métricas de qualidade de classificação (por exemplo taxa de falso positivo e
matriz de confusão) e métricas de escalabilidade (taxa de mensagens por segundo
e escalabilidade vertical ou horizontal). Além de seleção das métricas, alguns
desses trabalhos servirão para comparações e relacionamentos.

Na literatura técnica busca-se plataformas, ferramentas e técnicas para realizar
a implementação proposta, portanto, plataformas de processamento
distribuído de fluxos contínuos de dados, técnicas para implementação de
\emph{machine learning} nessas plataformas e técnicas ou ferramentas necessárias
para extração das métricas de avaliação.

De ambas (acadêmica e técnica) serão extraídos e selecionados \emph{datasets}
públicos relevantes para detecção de novidades em DS.

Com o estado da arte, ferramentas técnicas e \emph{datasets} definidos, é
desenvolvida uma aplicação multi-processada que, com base no algoritmo MINAS
\cite{Faria2016minas}, classifica e detecta novidades em DS com resultados de
classificação equivalentes à implementação original validando essa nova
aplicação.

Além disso, experimentos com a implementação e variações em \emph{datasets} e
cenários de distribuição em \emph{fog} coletando as métricas previamente
definidas. Os resultados serão comparados comparados entre si e com outros
trabalhos.

E ao final, a aplicação, resultados, comparações e discussões serão publicados
nos meios e formatos adequados como repositórios técnicos, eventos ou revistas
acadêmicas.

% Flink  - dizer que vai usar, para fazer o que e porque escolheu 

% Kafka ?

% Raspberry - para todos

% A base - 

% 1.2 (Cassales)
%  Metodologia
% A seguir será descrita a metodologia que pretende-se utilizar para atingir aos objetivos e
% responder às questões de pesquisa propostas.
% Primeiramente será realizado um levantamento do estado da arte no que diz respeito aos
% Sistemas de Detecção de Intrusão e às técnicas de Detecção de Novidade aplicadas aos Fluxos
% Contı́nuos de Dados. Com base neste levantamento, serão determinadas as lacunas dos sistemas
% da área e quais as técnicas mais adequadas para a utilização neste trabalho. Dado o foco nas
% técnicas e na arquitetura, é necessário que se possua mais de uma base de dados para realizar
% 1.2 Metodologia
%  13
% a avaliação. Tendo em vista que existem bases de dados de segurança que não representam
% o cenário atual de maneira fidedigna, é necessário selecionar bases que possibilitem que os
% resultados sejam confiáveis.
% Além das bases, serão utilizadas diversas técnicas, as quais deverão ser avaliadas e estuda-
% das para que possam ser propostas melhorias ou mesmo uma nova técnica. Finalmente, serão
% implementadas melhorias e, se necessário, uma nova técnica e será feita avaliação do desempe-
% nho desta técnica.

% \section{Organização do trabalho}

O restante desse trabalho segue a estrutura:
Capítulo \ref{cha:fundamentos} aborda conceitos teóricos e técnicos que embasam
esse trabalho;
Capítulo \ref{cha:related} enumera e discute trabalhos relacionados e estabelece
o estado da arte do tema detecção de novidade em fluxos de dados e seu processamento;
Capítulo \ref{cha:proposta} descreve a proposta de implementação, discute
as escolhas de plataformas e resultados esperados;
Capítulo \ref{cha:imp} discute os desafios e resultados preliminares encontrados
durante o desenvolvimento da aplicação;
Capítulo \ref{cha:crono} apresenta o cronograma de trabalho até a defesa.
