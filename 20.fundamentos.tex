% !TeX root = ./00.ppgcc-2020.tex

\chapter{Fundamentos Científicos e Tecnológicos}\label{cha:fundamentos}

Este Capítulo aborda conceitos que embasam esse trabalho,
conceitos teóricos de
ambientes e arquiteturas de computação distribuída e detecção de novidade
e conceitos técnicos, como plataformas de processamento distribuído de fluxo
de dados e o algoritmo MINAS.

\section{Ambientes de Computação Distribuída}

Esta \Section relaciona três ambientes de computação distribuída habitualmente
utilizados para o processamento de dados massivos relacionados a redes de
dispositivos \iot, entre outras aplicações.
A computação em nuvem (\cloud) é
aplicada a vários problemas e neste trabalho seu papel em sistemas \iot é
fornecer vastos recursos e garantias e em que dispositivos
enviam todos dados relevantes ao sistema.
O segundo e terceiro ambiente são computação de borda (\emph{edge computing})
e a computação em névoa (\emph{fog computing}), que utiliza os recursos
computacionais distribuídos presentes em nós localizados entre os dispositivos
de borda e a nuvem, com diversas 
intenções, desde privacidade até redução de latência.

% \subsection{Computação em Nuvem}

A computação em nuvem (\cloud), ou simplesmente nuvem
(\emph{cloud}), habilita o acesso através da rede a um grupo compartilhado de
recursos de computação configuráveis, como servidores, redes, aplicações,
armazenamento, etc.
Tais recursos podem ser provisionados ou liberados sob
demanda rapidamente com o mínimo esforço de gerenciamento
e mínima interação com o provedor destes recursos \cite{NIST2011}.

As principais características do ambiente \cloud, segundo \citeonline{NIST2011}
são: Serviço sob Demanda, Amplo acesso à rede, Agrupamento de recursos,
Elasticidade e Serviço mensurado.
Segundo, \citeonline{NIST2011}, a implantação da Computação em Nuvem pode
ocorrer através dos seguintes modelos: privada, comunitária, pública, híbrida.
Das implantações, a pública é a mais comum, sendo gerenciada e operada por um
provedor de nuvem e a infraestrutura é provisionada e oferecida para uso
público.

% \subsection{Computação de Borda}

A computação de borda (\emph{edge computing}) refere-se às
tecnologias que permitem que a computação seja executada na borda da rede.
Define-se borda ou \emph{edge} como qualquer recurso de computação e de rede ao
longo do caminho entre as fontes de dados e os data centers da nuvem
\cite{Shi2016}. Na borda, é possível fazer armazenamento, processamento e
descarregamento de dados, assim como distribuir as requisições e entregar os
serviços das nuvens aos usuários. \citeonline{Shi2016} ressalta que essas
capacidades (dentre outras) dos nós da borda (\emph{edge nodes}) possibilitam que a
computação de borda reduza a latência na resposta da nuvem, pré-processando os
dados nos nós da borda, aproveitando melhor a banda e a transmissão de dados, e
também consumindo menos recursos de computação na nuvem. Além disso, o autor
ainda acrescenta que a computação de borda pode aumentar a privacidade dos
dados, uma vez que eles podem ser processados no próprio dispositivo final.

A computação de borda tenta trazer a computação mais próxima das fontes de
dados.
Como é observado na figura, os
componentes desse tipo de computação podem ser tanto produtores como
consumidores, não só requisitando serviços e conteúdo da nuvem, mas também
realizando tarefas da nuvem.
Algumas aplicações da computação de borda incluem: análise de vídeo;
em sistemas críticos para redução de latência;
descarregar a nuvem de parte da computação;
privacidade dos dados produzidos, mantendo-os fora de ambientes públicos;
redução das cargas de dados na rede e
processamento distribuído de sensoriamento massivo em cidades inteligentes \cite{Shi2016}.

% \subsection{Computação em Névoa}

\citeonline{Dastjerdi2016} e \citeonline{IEEECommunicationsSociety2018}
mencionam que a enorme massa de dados gerados por ambientes IoT pode ser
processada em nuvem, entretanto a latência produzida pela transferência desses
dados para a nuvem e o retorno do resultado pode não ser toleradas por sistemas
críticos que sejam sensíveis a latência (monitoramento de saúde e resposta a
emergências).
\citeonline{IEEECommunicationsSociety2018} ainda acrescenta que enviar tantos
dados à nuvem
para processamento e armazenamento pode ser ineficiente e não escalável, devido à
saturação de dados na rede.
O ambiente \emph{edge computing} foi proposto para trazer o
processamento e armazenamento para os dispositivos de borda tentando solucionar
esses problemas.
Porém, dispositivos de borda comumente não podem lidar com várias
aplicações IoT competindo pelos seus recursos limitados, o que poderia causar a
contenção dos recursos e o aumento na latência do processamento
\cite{Dastjerdi2016}. Portanto, para solucionar estas questões de latência e
capacidade limitada dos dispositivos de borda, a computação em névoa foi proposta.

A computação em névoa (\emph{fog computing}) é um paradigma que distribui
as capacidades de computação, armazenamento e rede entre os nós próximos
das fontes dados
e dos dispositivos finais, mas não necessariamente localizados na borda,
dando a esses nós características de uma nuvem
\cite{Bonomi2012,Dastjerdi2016,IEEECommunicationsSociety2018}.
Esse tipo de computação evita a sobrecarga dos dispositivos de borda.
\citeonline{Bonomi2012} e
\citeonline{Dastjerdi2016} consideram computação em névoa como complementar da
computação em borda, podendo a computação em névoa aproveitar os recursos da
nuvem e da borda.
\citeonline{IEEECommunicationsSociety2018} considera que a
principal diferença entre esses dois tipos de computação está no número de
camadas.
Enquanto \emph{edge computing} tem
camadas menores, pois atua só nos
dispositivos de borda, \emph{fog computing} tem mais camadas e um modelo
hierárquico, pois não atua só na camada de borda.

Segundo \citeonline{Bonomi2012} e \citeonline{Dastjerdi2016}, as principais
características da computação em névoa são:

\begin{itemize}

    \item \textbf{Mobilidade:} é essencial que as aplicações \emph{fog} sejam
    capazes de se comunicar com dispositivos móveis, por exemplo, utilizando
    protocolos que considerem a mobilidade dos nós;

    \item \textbf{Heterogeneidade:} os nós nesse tipo de paradigma possuem
    configurações e formatos diferentes e podem estar implantados em ambientes
    distintos;

    \item \textbf{Baixa Latência:} \hlhl{computação em névoa} foi proposta para
    atender aplicações que requeiram baixa latência (monitoramento de saúde,
    jogos, realidade aumentada, etc.);

    \item \textbf{Distribuição geográfica:} computação em névoa pode possuir
    milhares de sensores e dispositivos distribuídos geograficamente, com
    consciência de suas localizações (\emph{location awareness});

    \item \textbf{Alto número de nós:} seguindo os ambientes IoT, a computação
    em névoa pode ser composta por milhares de nós;

    \item \textbf{Interoperabilidade e federação:} os componentes da computação
    em névoa devem ser capazes de interoperar, e o serviços devem ser federados
    \hlhl{ao longo de diferentes domínios};

    \item \textbf{Uso de fluxo de dados e aplicações em tempo real:} a
    computação em névoa pode envolver aplicações que processam em lote, mas na
    maior parte das vezes envolve aplicações com requisito de processamento em
    tempo real, e para isso fazem o uso de fluxo de dados. Por exemplo, os
    sensores de um rede IoT escrevem a informação no fluxo de dados, a
    informação é processada, ações são inferidas e traduzidos em
    ações nos componentes atuadores.

\end{itemize}

Algumas aplicações para computação em névoa são:
cidades inteligentes e
semáforos inteligentes que enviam sinais de alerta aos veículos e coordenam os
sinais verdes com outros semáforos através de sensores (veículos, pedestres,
ciclistas);
na área de saúde, para monitorar e prever situações de pacientes que
estão conectados a sensores;
em prédios inteligentes, que são dotados de sensores
de umidade, temperatura, qualidade do ar, ocupação, sendo que a partir das
informações deles, é possível alertar os ocupantes do prédio em algum caso de
emergência.

\section{Mineração de Dados e Fluxo de Dados}

A Mineração de Dados é o processo de descoberta de padrões em conjuntos de dados
utilizando métodos derivados de aprendizagem de máquina, estatística e banco de
dados \cite{Gaber2005}.
Além de mineração de dados tradicional, \emph{Big Data} trata de
conjuntos de dados que não podem ser processados em tempo viável, devido a limitações
como memória ou armazenamento principal.

\begin{definition}
    Um \textit{Fluxo de Dados} $S$ é uma sequência massiva, potencialmente
    ilimitada de exemplos multi-dimensionais
    $\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_n, \dots$
    recebida em instantes
    $\mathbf{T}_1, \mathbf{T}_2, \dots, \mathbf{T}_n, \dots$
    \cite{Aggarwal2003}.
\end{definition}

Além da dimensão de armazenamento, outra dimensão que afeta a maneira como dados
são modelados e manipulados é o tempo.
Técnicas e algoritmos de mineração de fluxo de dados atendem a esses desafios utilizando
restrições como apenas uma leitura do conjunto de dados e baixo tempo de
processamento na construção de seus algoritmos \cite{Gama2007, Gaber2005}.

As características de fluxos de dados e mineração de dados e os requisitos de
seu processamento regularmente superam as capacidades computacionais de um único
nó computacional convencional, de forma que a distribuição dos requisitos em
múltiplos nós computacionais em um sistema distribuído pode ser necessária
\cite{Gaber2005}.

% Computação distribuída é a área da ciência da computação que estuda sistemas
% em que os componentes são localizados em diferentes computadores (nós), que
% comunicam-se apenas por troca de mensagens e, para que o objetivo do sistema
% seja atingido, a cooperação entre os nós é necessária.
% Outras propriedades de um sistema distribuído são a concorrência entre os nós e
% possibilidade de
% falhas em partes independentes \cite{TanenbaumSteen2018}.

Para a construção de sistemas que apliquem técnicas de mineração de fluxos de
dados são necessárias bibliotecas e plataformas (\emph{frameworks})
que são abordadas na \refsec{frameworks}.

\section{Arquiteturas e Plataformas de Processamento de Fluxos}
\label{sec:frameworks}

Tradicionalmente, aplicações
foram construídas com um sistema gerenciador de
banco de dados (SGBD) relacional ou não-relacional associado.
Essa arquitetura,
nomeada de ``arquitetura totalmente incremental'' por \citeonline{marz2015big},
foi evoluída e simplificada iterativamente durante décadas de uso, porém ela não
é adequada para sistemas em tempo real, como os sistema de fluxo de dados.
O volume e a velocidade de dados em um \emph{Data Stream} leva à necessidade de
distribuir o processamento, acrescentando poder computacional a cada nó
adicionado.
Porém, desafios como comunicação eficiente e sincronização de estado
entre os nós, assim como tolerância a falhas, aumentam a complexidade de
construção de um sistema distribuído em relação a um sistema tradicional.

\newcommand{\lambdaa}{\xspace\emph{Lambda}\xspace}
\newcommand{\kappaa}{\xspace\emph{Kappa}\xspace}

Para mitigar problemas associados à construção de sistemas \emph{Big Data}
e \emph{Data Streams},
arquiteturas de processamento de fluxo
de dados distribuído foram propostas, como a arquitetura \lambdaa
\cite{marz2015big} e \kappaa \cite{Kreps2014}, além
de
diversas plataformas, tanto de \emph{Big Data} com características de tempo real,
como especializadas em fluxo de dados.

\emph{MapReduce} é a primeira plataforma de processamento de conjuntos massivos
de dados que atingiu uso generalizado.
Nessa implementação, uma biblioteca gerencia a distribuição, paralelização,
tolerância a falhas e balanceamento de carga.
Ao usuário da biblioteca resta implementar duas funções:
\emph{Map}, que recebe um par ordenado
$(chave, valor)$ e emite um conjunto de pares intermediários na mesma estrutura;
\emph{Reduce}, que recebe uma chave e um conjunto de valores gerado pelo agrupamento
de pares com essa mesma chave \cite{Dean2004}.

Em prática, um \emph{cluster MapReduce} tem centenas de processadores e o
conjunto de dados é armazenado em um sistema de arquivos distribuído que é lido
pela plataforma com programas escritos por usuários sendo executados sob
supervisão de um nó mestre.
Essa implementação tem esquema geral de processamento em lotes que não atende o
requisito de baixa latência.
\nobreakdash \emph{MapReduce} é uma das principais influências na criação da arquitetura
\lambdaa \cite{marz2015big}.

\emph{Apache Hadoop} é uma coleção de ferramentas, incluindo: \emph{Hadoop
Distributed File System} (HDFS, um sistema de arquivos distribuído), \emph{Hadoop
YARN} um gerenciador de recursos em cluster e escalonador de trabalhos e,
\emph{Hadoop MapReduce}, um sistema baseado em \emph{YARN}, implementando o modelo
\emph{MapReduce} \cite{ApacheHadoop2020}.

\emph{Apache Spark}, analogamente ao \emph{Hadoop}, é um \emph{framework} para
construção de sistemas de computação distribuída em \emph{cluster}, com garantias
de tolerância a falhas.
No entanto, o modelo de processamento diverge
significativamente do tradicional \emph{MapReduce}, utilizando em lugar do HDFS
um multiconjunto imutável distribuído (\emph{Resilient Distributed Dataset}
- RDD) com um escalonador de trabalhos representados por grafos acíclicos
direcionados (\emph{directed acyclic graph} - DAG), otimizador de consultas e
motor de execução \cite{ApacheSpark2020}.

Uma das extensões de \emph{Apache Spark} é \emph{Spark Streaming}, que é um
sistema de processamento de fluxo de dados 
escalável e tolerante a falhas
\cite{zaharia2016,sparkStreaming2016}.
\emph{Spark Streaming} implementa processamento incremental de fluxo de
dados usando o modelo de fluxos discretizados em que dividem-se os dados de entrada
em micro-lotes (ex: a cada 100 milissegundos) e combinam-se regularmente com o
estado nos RDDs para produzir novos resultados \cite{zaharia2016}.
Essa estratégia traz benefícios sobre os sistemas de fluxos de dados distribuídos
tradicionais, pois permite a consistência e recuperação de falhas rapidamente,
devido à \notahl{?}\hlhl{linhagem de RDD} (\emph{RDD lineage})
e à combinação do fluxo de dados com
consultas em lotes e interativas \cite{sparkStreaming2016,Lopez2018}.

\emph{Apache Storm} é um sistema de computação tolerante a falhas em tempo
real que \notahl{quem disse?!}\hlhl{facilita o processamento} de fluxo de dados
\cite{ApacheStorm2020,Lopez2018}.
Ao invés de executar trabalhos (\emph{jobs}) como algumas ferramentas citadas
anteriormente, \emph{Apache Storm} \notahl{?}\hlhl{executa topologias}.
Os \emph{jobs} eventualmente finalizam, e as topologias executam continuamente até
serem finalizadas por comandos.
Uma topologia constitui-se de processos trabalhadores (\emph{workers}) sendo executados
em um \emph{cluster} de nós que são gerenciados pelo nó mestre que além de
coordenar e distribuir execução, monitora falhas.
Uma topologia pode ser representada por um grafo de computação direcionado
acíclico (DAG).

O \emph{Apache Flink} é uma plataforma de processamento distribuído para
computação com estado gerenciado (\emph{stateful}) sobre fluxo de dados limitados (têm início e
fim) e ilimitados (não têm fim definido) \cite{ApacheFlink2020}.
Essa plataforma segue um paradigma que abrange o processamento de fluxos de
dados contínuos e o processamento em lote \cite{Carbone2015,Lopez2018}.
O \emph{Apache Flink} pode ser integrado a vários gerenciadores de \emph{cluster}
comuns, como \emph{Hadoop Yarn}, \emph{Apache Mesos}, e \emph{Kubernetes}, mas também pode ser
configurado para ser executado como um \emph{cluster stand-alone}.
Já o acesso programático a essa plataforma pode ser feito através das linguagens
Java, Scala ou Python.

\subsection{\emph{Interface de Troca de Mensagens - MPI}}

\mpi é um padrão com algumas implementações que permite a construção de um
sistema distribuído com um executável único (monólito) utilizando com abstração
a passagem de mensagens.

Modelo de programação (SPMD vs ), modelo de comunicação (empacotamento,
localização de dados).

Configuração de execução.
