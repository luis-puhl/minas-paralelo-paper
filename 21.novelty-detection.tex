\section{Detecção de Novidade}\label{sec:nd}

No âmbito de classificação de dados, parte da área de aprendizado de máquina, os
métodos de detecção de novidade (\novelty, \nd) lidam com o reconhecimento e a
classificação de exemplos que diferem de exemplos anteriores
\cite{Perner2009,Gama2010}.
Esses métodos tratam da classificação em fluxos de dados que evoluem com o
tempo, levando em consideração as características desse tipo de fluxos.

Tratando-se de fluxos de dados contínuos, são características
dos padrões observados:
evolução de conceito (\evolution) em que novos padrões podem surgir;
desaparecimento ou recorrência de conceito, em que padrões podem desaparecer e
também podem reaparecer;
mudança de conceito (\drift, também nomeado deriva ou desvio) onde um padrão
gradualmente se transforma;
presença de ruído e \emph{outliers} \cite{Gama2010}.

Os métodos de \nd são aplicados a diversos problemas como
detecção de intrusos \cite{Coull2003,Spinosa2008,Viegas2019,Cassales2019a},
detecção de falhas \cite{Zhang2006},
diagnósticos médicos \cite{Perner2009},
detecção de regiões de interesse em imagens \cite{singh2004approach},
detecção de fraudes \cite{wang2003mining,Abdallah201690}, 
filtros de spam \cite{Hayat2010dct} e
detecção de variações comportamentais em um jogador \cite{Vallim20136258}.

Alguns métodos de \nd utilizam tratam de novidades como uma classificação de uma
ou duas classes (binariamente) onde um conceito representa a classe normal e as anomalias
são representadas pela falta de conceito no modelo ou como um segundo conceito
no modelo.
Além da abordagem de classificação binária, múltiplos conceitos em um mesmo
conjunto de dados, para isso é necessário abordar \nd como classificação
multi-classe.
Alguns métodos que abordam \nd como classificação multi-classe não
atendem completamente características de conjuntos com 
evolução temporal,
como \evolution e \drift, deixando de detectar múltiplos padrões que surgem
simultaneamente num intervalo de avaliação \cite{Faria2016ndds,Gama2010}.

A maioria dos métodos de \nd são construídos seguindo a abordagem de aprendizado
\emph{Offline-Online}. Essa abordagem estabelece que o método seja dividido em
duas fases:
a primeira fase (\emph{Offline}) usa um conjunto de exemplos rotulados para
deles extrair conceitos conhecidos e gerar um modelo;
a segunda fase (\emph{Online}) consome um conjunto ou fluxo de exemplos não
rotulados e detecta padrões-novidade.
Além de detectar padrões-novidade, alguns algoritmos classificam cada exemplo
em um dos conceitos do modelo, ou marca o exemplo como desconhecido.
Ainda na segunda fase, para atualizar o modelo, os exemplos marcados como
desconhecidos são utilizados para a extração de novos conceitos ou variações em
conceitos conhecidos \cite{Gama2010}.

Dentre os métodos de \nd que baseiam-se em aprendizado \emph{Offline-Online},
muitos são baseados em algoritmos de agrupamento não supervisionados, tanto
para construção do modelo inicial como na extração de novos conceitos dos
exemplos não explicados pelo modelo marcados como desconhecidos
\cite{Spinosa2009ollinda,Masud2010ECSMiner,Faria2013}.

\subsection{O algoritmo MINAS}\label{sec:minas-og}

Um algoritmo de \nd que tem recebido atenção nos últimos anos é o algoritmo
MINAS, originalmente proposto por \citeonline{Faria2013}, refinado por
\citeonline{Faria2016minas} e recentemente aprimorado por
\citeonline{DaSilva2018thesis}, com o uso de conceitos \emph{Fuzzy}, e expandido por
\citeonline{Costa2019thesis}, para tratar problemas multi-rótulo além dos problemas
multi-classe já tratados na versão original.
Esse algoritmo segue a abordagem de duas fases no modelo \emph{Offline-Online} e
usa por base algoritmos de agrupamento não supervisionados como \emph{K-means} e
\emph{CluStream}.

\newcommand{\mcluster}{\emph{micro-cluster}\xspace}
\newcommand{\mclusters}{\emph{micro-clusters}\xspace}

O algoritmo MINAS em sua fase \emph{Offline} consome um conjunto de treinamento
contendo exemplos etiquetados.
Esse conjunto de treinamento é dividido em grupos usando como chave a etiqueta,
e para cada grupo de exemplos o método de agrupamento (\emph{clustering}) é executado.
O método de agrupamento objetiva resumir um conjunto maior de exemplos em
um conjunto menor de \mclusters.

Um \mcluster é uma tupla de quatro components $(N, \mathbf{LS}, \mathbf{SS}, T)$
derivados dos exemplos representados por este \mcluster, onde:
$N$ número de exemplos,
$\mathbf{LS}$ soma linear dos exemplos,
$\mathbf{SS}$ soma quadrada dos exemplos,
$T$ instante de chegada do último exemplo adicionado ao \mcluster.
Deste sumário extrai-se, entre outras estatísticas, o centro e raio que são
utilizados na operação de classificação da fase \emph{Online}.
A cada \mcluster é adicionada a etiqueta do grupo original e todos \mclusters
são arranjados em um único conjunto formando o modelo de decisão.

Na fase \emph{Online}, listada no Algoritmo \ref{alg:minas-main}, o algoritmo MINAS
opera com três operações: classificação de novos exemplos, detecção de 
padrões-novidade e atualização do modelo de decisão \cite{Faria2016minas}.
O primeiro método é o de classificação, onde exemplos do fluxo de dados
são consumidos e avaliados pelo modelo de decisão.
O modelo de decisão avalia cada exemplo calculando a distância euclidiana
entre o exemplo e todos \mclusters do modelo, selecionando o
\mcluster de menor distância.
Se a distância entre o exemplo e o centro do \mcluster for menor que
o raio do \mcluster, o exemplo é classificado com a etiqueta do \mcluster
e o sumário estatístico do \mcluster é atualizado.
Caso a distância (mínima no modelo) seja maior que o raio,
o exemplo é marcado como desconhecido e armazenado
em conjunto próprio \cite{Faria2016minas}.

O segundo método da fase \emph{Online} é a detecção de padrões novidade,
que é executada quando o tamanho do conjunto de desconhecidos é maior
que um parâmetro predefinido.
Esse método executa o agrupamento (\emph{clustering} descrito na fase
\emph{Offline}) e valida os \mclusters gerados verificando sua representatividade
e coesão.

% \subsection{MINAS}
% \label{sec:minas}

\minas \cite{Faria2016minas} is an offline-online \nd algorithm,
meaning it has two distinct phases. The first phase (offline) creates an initial
model set with several clusters based on a clustering algorithm with a training
set.
Each cluster can be associated with only one class of the problem, but each
class can have many clusters.

During its online phase, which is the main focus of our work, \minas performs
three tasks in (near) real-time,
in summary,
classification, novelty detection, and model update tasks
in a potentially infinite data stream, as shown in Algorithm \ref{alg:minas-main}.

\minas attempts to classify each incoming unlabeled instance according to the
current decision model. Instances not explained by the current model
receive an \textit{unknown} label and are stored in an unknowns-buffer.
When the unknowns-buffer reaches a preset threshold, \minas executes the
Novelty Detection function.
After a set interval, samples in the unknowns-buffer are considered to be
noise or outliers and removed.
The algorithm also has a mechanism to forget clusters that became obsolete and
unrepresentative of the current data stream distribution, removing them from
the Model and storing in a Sleep Model for possible recurring pattern
detection \cite{Faria2016minas}.

\begin{algorithm}[htb]
    % \DontPrintSemicolon
    \SetKwFunction{nearestCluster}{nearestCluster}
    \SetKwFunction{clustering}{clustering}
    \SetKwFunction{NoveltyDetection}{NoveltyDetection}
    \SetKwFunction{handleModelSleep}{moveToSleep}
    \SetKwFunction{removeOldSamples}{removeOldSamples}
    % 
    \SetKwProg{Function}{Function}{:}{}
    \SetKwFor{With}{with}{}{}
    \SetKw{continue}{continue}
    % 
    \KwIn{ModelSet, inputStream}
    \KwOut{outputStream}
    % 
    \SetKwData{cleaningWindow}{cleaningWindow}
    \SetKwData{noveltyDetectionTrigger}{noveltyDetectionTrigger}
    \SetKwInOut{KwParams}{Parameters}
    \KwParams{\cleaningWindow, \noveltyDetectionTrigger}
    % \KwSty{Parameters}: \cleaningWindow, \noveltyDetectionTrigger\\
    % 
    \SetKwFunction{MinasOnline}{MinasOnline}
    \Function{\MinasOnline{ModelSet, inputStream}}{
        UnkownSet $\leftarrow$ $\emptyset$, ModelSleepSet $\leftarrow$ $\emptyset$ \;
        lastCleanup $\leftarrow 0$ , noveltyIndex $\leftarrow 0$\;
        % sampleIn $\leftarrow 0$\;
        \ForEach{ {$sample_{i}$} $\in$ inputStream }{
            % sample.label $\leftarrow$ unknown\;
            % (distance, cluster) $\leftarrow$ \nearestCluster(sample, ModelSet)\;
            nearest $\leftarrow$ \nearestCluster(sample, ModelSet)\;
            \eIf{nearest.distance $<$ nearest.cluster.radius}{
                sample.label $\leftarrow$ nearest.cluster.label\;
                nearest.cluster.lastUsed $ \leftarrow i $ \;
            }
            {
                sample.label $\leftarrow$ unknown\;
                UnkownSet $\leftarrow$ UnkownSet $\cup$ sample\;
                \If{$|\;UnkownSet\;| \geq$ \noveltyDetectionTrigger}{
                    % \tcc{Novelty Detection}
                    novelties $\leftarrow$ \NoveltyDetection(ModelSet $\cup$ ModelSleepSet, *UnkownSet)\;
                    ModelSet $\leftarrow$ ModelSet $\cup$ novelties\;
                }
                \If{ $ i > $ ( lastCleanup $ + $ \cleaningWindow )}{
                    ModelSet $\leftarrow$ \handleModelSleep(ModelSet, *ModelSleepSet, lastCleanup)\;
                    UnkownSet $\leftarrow$ \removeOldSamples(UnkownSet, lastCleanup)\;
                    lastCleanup $ \leftarrow i $\;
                }
            }
            outputStream.append(sample)\;
        }
    }
\caption{Our interpretation of \minas baseado em \cite{Faria2016minas}}
\label{alg:minas-main}
\end{algorithm}

The Novelty Detection function, illustrated in Algorithm \ref{alg:MINAS-nd},
groups the instances to form new clusters, and each new cluster is validated to
discard the non-cohesive or unrepresentative ones.
Valid clusters are analyzed to decide if they represent an extension of a
known pattern or a completely new pattern. In both cases, the model absorbs the
valid clusters and starts using them to classify new instances.

\begin{algorithm}[htb]
    \SetKwProg{Function}{Function}{:}{}
    \SetKwData{minExamplesPerCluster}{minExamplesPerCluster}
    \SetKwData{noveltyFactor}{noveltyFactor}
    \SetKwInOut{KwParams}{Parameters}
    \KwParams{\minExamplesPerCluster, \noveltyFactor}
    % 
    \SetKwFunction{nearestCluster}{nearestCluster}
    \SetKwFunction{clustering}{clustering}
    \SetKwFunction{NoveltyDetection}{NoveltyDetection}
    \SetKwFunction{handleModelSleep}{moveToSleep}
    \SetKwFunction{removeOldSamples}{removeOldSamples}
    % 
    \Function{\NoveltyDetection{Model, Unknowns}}{
        newModelSet $\leftarrow$ $\emptyset$\;
        \ForEach{cl in \clustering(Unknowns)}{
            \If{$|\;cl.sampleSet\;| \geq$ \minExamplesPerCluster}{
                (distance, near) $\leftarrow$ \nearestCluster(cl, Model)\;
                \eIf{distance $<$ near.radius $\times$ \noveltyFactor}{
                    cl.label $\leftarrow$ near.label\;
                    cl.type $\leftarrow$ extension\;
                }{
                    cl.label $\leftarrow$ noveltyIndex\;
                    noveltyIndex $\leftarrow$ noveltyIndex $+ 1$\;
                    cl.type $\leftarrow$ novelty\;
                }
                Unknowns $\leftarrow$ Unknowns $-$ cl.sampleSet\;
                \label{alg:MINAS-nd:reclassify}
                newModelSet $\leftarrow$ newModelSet $\cup$ cl\;
            }
        }
        \Return{newModelSet}\;
    }
    \caption{\minas \cite{Faria2016minas} Novelty Detection task.}
    \label{alg:MINAS-nd}
\end{algorithm}

Para atribuição de etiquetas aos \mclusters gerados, o algoritmo MINAS
encontra no modelo atual o \mcluster mais próximo pela distância
euclidiana e classifica em dois tipos de conceito.
Se a distância é menor que um parâmetro predefinido,
o novo \mcluster gerado recebe como etiqueta o valor de extensão
de conceito conhecido.
Caso contrário, se o novo \mcluster está mais distante,
um novo conceito foi encontrado e a etiqueta marca um padrão novidade.
Após a atribuição da etiqueta do novo \mcluster, ele é adicionado
ao modelo de decisão.

O algoritmo MINAS, como já foi discutido na Seção \ref{sec:minas-og}, classifica
exemplos e detecta
novidades em DS e considera em sua composição \emph{concept drift} e
\emph{concept evolution}, sendo capaz de classificar como extensão de classe
conhecida e identificar padrões novidade sem intervenção de especialista
\cite{Faria2016minas}.
Neste trabalho, consideram-se algoritmos derivados do algoritmo MINAS
aqueles apresentados em trabalhos publicados após 2016, que estendem a
implementação original seguindo sua estrutura básica.

O MINAS foi relevante e motivou extensões como \cite{DaSilva2018,Costa2019}.

% \subsubsection{Algoritmo Extensão FuzzyND}

% O algoritmo FuzzyND, derivado do MINAS foi proposto por \citeonline{DaSilva2018}.
% FuzzyND incrementa o algoritmo original, aplicando a ele teorias de
% conjuntos \emph{fuzzy} pela modificação da representação dos \clusters.
% A modificação afeta o método de construção de \clusters, método de classificação
% de exemplos e método de detecção de novidades de acordo com a nova representação.

% A avaliação do algoritmo FuzzyND foi feita por meio de experimentos usando 3 
% \datasets sintéticos (\emph{MOA3}, \emph{RBF}, \emph{SynEDC})
% e por comparação com o MINAS.
% O método de avaliação utilizado baseia-se na matriz de confusão incremental
% descrita por \citeonline{Faria2016ndds}, extraindo dessa matriz duas métricas:
% acurácia (\emph{Macro F-Score}) \cite{Sokolova2009} e
% taxa de desconhecidos (\emph{UnkR}) \cite{Faria2016minas}.
% Em geral, o algoritmo FuzzyND detecta melhor novidades e, consequentemente,
% é mais robusto a valores atípicos (\emph{outlier}), porém perde a capacidade
% de reconhecer padrões recorrentes.

% \subsubsection{Algoritmo Extensão MINAS-LC e MINAS-BR}
% \label{sub:minas-derivados}

% O algoritmo MINAS-LC foi proposto por \citeonline{Costa2019thesis} e trata a classificação
% multi-rótulo, porém não trata evoluções de conceito (\emph{Concept Evolution}).
% As alterações fundamentais propostas são:
% a representação de \cluster onde MINAS-LC troca a etiqueta, que era única, por uma multi-rótulo;
% a transformação de problema aplicada ao conjunto de treinamento para transformá-lo de um
% conjunto multi-rótulo para um conjunto multi-classe (simplificação)
% em duas variações \emph{Label Powerset} e \emph{Pruned Sets} com
% mineração de conjunto de itens frequentes.

% Já o trabalho de \citeonline{Costa2019}, estende o algoritmo original para que
% classifique um exemplo com uma ou mais etiquetas usando a transformação
% \emph{Binary Relevance}, o que deu origem ao algoritmo MINAS-BR.
% O algoritmo modifica a representação do modelo, originalmente conjunto de \clusters, para
% um grupo de \clusters por classe (etiqueta).
% Também modifica o método de agrupamento, substituindo a inicialização do 
% algoritmo \emph{K-means}, originalmente aleatória, pelo algoritmo 
% \emph{Leader Incremental Clustering} \cite{Vijaya2004505}.

% O algoritmo MINAS-BR também é experimentalmente avaliado com 4 \emph{data sets}
% sintéticos: \emph{MOA-3C-5C-2D}, \emph{MOA-5C-7C-2D}, \emph{MOA-5C-7C-3} da
% ferramenta MOA \cite{MOA} e \emph{4CRE-V2}
% \footnote{
%     A versão original do \dataset 4CRE-V2 está disponível em
%     \url{https://sites.google.com/site/nonstationaryarchive/home}.
% }
% gerados pelo método \emph{Radial Basis Function} \cite{souza2015,Costa2019}.
% O algoritmo MINAS-BR foi comparado com 7 algoritmos da literatura também
% disponíveis na ferramenta MOA \cite{MOA}, diferente da avaliação do FuzzyND que
% compara diretamente com MINAS. Para análise, os 7 algoritmos foram divididos em
% dois grupos \cite{Costa2019}.
% O primeiro grupo de 3 algoritmos com acesso às etiquetas corretas para
% atualização do modelo e com a técnica ADWIN (\emph{ADaptive WINdowing}) para detectar
% mudanças de conceito (\emph{Concept Drift})
% O segundo grupo com os 4 algoritmos sem acesso às etiquetas corretas,
% ou seja, sem \emph{feedback} externo, mesma condição do MINAS-BR \cite{Costa2019}.

% A avaliação elencada por \citeonline{Costa2019} leva em consideração que as classes
% contidas no conjunto de testes podem não ter correlação direta com os padrões identificados
% pelos algoritmos.
% Para tratar a divergência, uma estratégia baseada em proposta anterior por
% \citeonline{Faria2016ndds} foi apresentada com alterações para exemplos multi-rótulo.
% Após associação entre padrões de novidade e classes novidade foi possível calcular
% métricas tradicionais.
% A estratégia é executada na fase de classificação seguindo as regras:

% \begin{enumerate}

%     \item após o consumo do exemplo $X_n$;
    
%     \item para todo padrão $P_i$ (etiqueta atribuída) identificado sem
%     associação até o momento;
    
%     \item com classes novidade $y_j$ (etiqueta real) presentes em exemplos antes
%     $X_n$;
    
%     \item preenche-se a tabela de contingência $\mathbf{T}_{(i,j)}$ relacionando
%     padrão $P_i$ e classe $y_j$;
    
%     \item calcula-se o grau de dependência $\mathit{F1}$ derivado da tabela de
%     contingência $\mathit{F1}_{(i,j)} = f(\mathbf{T}_{(i,j)})$;
    
%     \item valores $\mathit{F1}_{(i,j)} = 0$ são descartados;
    
%     \item dentre os valores restantes: o padrão $P_i$ é associado à classe $y_j$
%     se $\mathit{F1}_{(i,j)}$ é máximo.

% \end{enumerate}

% As métricas utilizadas por \citeonline{Costa2019} após a associação de classes e
% padrões são as tradicionais taxa de desconhecidos (\emph{UnkRM}) e \emph{F1M}.
% Os resultados apresentados indicam que MINAS-BR capturou todas as novidades dos
% \datasets sintéticos de teste e mostrou, como esperado, melhores métricas que os
% 4 algoritmos equivalentes da literatura ficando abaixo dos 3 com \emph{feedback}
% externo.

% Os trabalhos abordados nessa \refsec{nd}, têm em
% comum, além do algoritmo base, as métricas de avaliação acurácia (\emph{Macro F-Score} e \emph{Macro
% F-Measure} F1M) e taxa de desconhecidos, aplicadas com devido tratamento.
% Também é comum entre eles o uso de \datasets sintéticos.
% Outro potencial não explorado do MINAS é em aplicações reais, ou seja,
% consumindo além de \datasets reais, fluxos realistas em ambientes simulados ou
% reais porém considerando uso de recursos computacionais.

% Observando a arquitetura dos algoritmos abordados na \refsec{nd}, nota-se as semelhanças:
% a fase offline centrada no processo de agrupamento e criação de modelo;
% a fase online dividida em classificação (com atualização das estatísticas do modelo)
% e detecção de padrões, onde novamente o processo de agrupamento é central.
% Portanto, apesar de outros trabalhos expandirem o algoritmo com diferentes técnicas, seu
% núcleo continua relevante.

Algumas propostas de modificação do algoritmo MINAS notáveis discutidas durante o desenvolvimento
deste trabalho 
% Não cabe ao presente trabalho expandir e validar conceitos de aprendizagem de máquina,
porém alguns exemplos mencionados não abordados são \cite{DaSilva2018,DaSilva2018thesis,Costa2019}:

\begin{enumerate}[label={\alph*)}]
    
    \item diferentes métodos de cálculo de distância entre pontos além da
    distância euclidiana;
    
    \item a mudança de representação de \clusters, atualmente hiper-esferas
    \cite{Costa2019thesis}, para hiper-cubos tratando \datasets onde as
    características representadas pelas dimensões são completamente
    independentes;
    
    \item um modo interativo onde o \cluster é formado, mostrado ao especialista
    que o classifica como inválido (ruído ou não representativo) ou válido,
    podendo conter uma ou mais classes e, se contiver mais que uma classe corte em
    grupos menores até conter somente uma classe;
    
    \item ainda considerando interação com especialista, a possibilidade de
    injetar um exemplo não pertencente a uma classe, ou seja, marcar o exemplo
    como não pertencente a uma classe para mantê-lo na memória de
    desconhecidos e, eventualmente forçar criação de um \cluster que represente
    uma classe geometricamente próxima mas semanticamente distinta;
    
    \item na fase \emph{offline} a verificação de sobreposição de \clusters
    pertencentes a classes distintas e tratamento adequado.

\end{enumerate}

Link com este trabalho, estes trabalhos foram importantes para entender MINAS e, apesar de
abordar ML, ajudaram a construir uma ideia geral do algoritmo e como proceder para criação
de uma versão distribuída.
