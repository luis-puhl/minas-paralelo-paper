% !TeX root = ./00.ppgcc-2020.tex

% \chapter{Implementação}\label{cha:implementacao}

% % procedimento experimental previamente definido de ambos, \mfog e da
% % implementação original do algoritmo MINAS, e comparadas.

% \input{52.preliminares.tex}
% \input{53.mpi.tex}

\chapter{Experimentos e Resultados}\label{cha:results}

Este capítulo apresenta o ambiente experimental e os resultados obtidos dos
experimentos, discutindo as métricas de qualidade da classificação e
escalabilidade do \mfog.

\input{51.ambiente.tex}
% \input{54.experimentos.tex}

% \FloatBarrier
\section{Experimentos, Métricas e Visualizações}
\label{sec:experiments}
% acho que convém explicar as demais tabelas de resultados...

\newcommand{\expA}{\textit{a-Referência}\xspace}
\newcommand{\expB}{\textit{b-Sequencial}\xspace}
\newcommand{\expC}{\textit{c-Paralelo}\xspace}
\newcommand{\expD}{\textit{d-Distribuído}\xspace}

Seguindo as especificações de ambiente da Seção \ref{sec:ambiente}, cada
experimento consiste na execução de um dos programas,
% ((a) \minas referência 2013
% \cite{Faria2013source}, (b) implementação sequencial do \minas com a nova
% biblioteca, (c) \mfog em um ou (d) três nós) 
com variação do parâmetro de paralelismo, como mostra a Tabela \ref{tab:exp-list},
fornecendo um modelo inicial e \dataset de teste como fluxo de entrada e
capturando o fluxo de saída para e extração das métricas estabelecidas na Seção
\ref{sec:avaliacao}.
Destes experimentos os seguintes resultados são apresentados.

\begin{table}[htb]
  \centering
  % \setlength\tabcolsep{0.5em}
  \caption{Listagem dos principais experimentos.}
  \label{tab:exp-list}
  \begin{tabular}{p{0.17\textwidth}|p{0.27\textwidth}|p{0.47\textwidth}}
  \textbf{Experimento} & \textbf{Programa}                 & \textbf{Características} \\\hline
  \expA                & \minas referência 2013            & Raio é a distância máxima. \\\hline
  \expB                & \minas sequencial para validação  & 
    Raio é o desvio padrão das distâncias;
    Modelo único;
    Remoção de desconhecidos mais agressivo. \\\hline
  \expC                & \mfog 1 nó, 4 processadores       & 
    Classificadores paralelos;
    Detecção de novidade assíncrona. \\\hline
  \expD                & \mfog 3 nós, 12 processadores     &
    Mais processadores;
    Comunicação em rede.
  \end{tabular}
\end{table}

\subsection{Validação do algoritmo}

Para validar a biblioteca de funções do \mfog que implementa o algoritmo \minas,
uma versão do Algoritmo \ref{alg:minas-main} foi construída, sem classificadores
paralelos ou detecção de novidade assíncrona, aspectos que caracterizam o \mfog.
Esta implementação utiliza a definição de raio da Equação \ref{eq:raio_paper}
(desvio padrão das distâncias).
Feita esta implementação foram realizados os experimentos \expB com esta
implementação e \expA com a implementação \minas referência (\refminas).
Estes dois experimentos utilizam apenas um nó e um processador do ambiente
experimental, sendo que as métricas são extraídas conforme a \refsec{avaliacao}
e são comparadas nesta Subseção, mostrando a equivalência entre as implementações.

A Tabela \ref{tab:java-matrix} mostra a matriz de confusão no instante final do
fluxo de saída do experimento \expA.
Nesta matriz, o rótulo ``desconhecido'' é o caractere ``$-$'', os valores de
associação e verdadeiro-positivo estão atrelados à coluna de cada rótulo e no
demais a matriz segue os atributos definidos na Seção \ref{sec:avaliacao}.
Esta matriz é comparada com a matriz de confusão do mesmo instante do fluxo de
saída do experimento \expB, vista na Tabela \ref{tab:libc-matrix}.

\begin{table}[hbt]%{\linewidth}
  {\footnotesize
  % \setlength\tabcolsep{0.5em}
  \begin{center}
  \caption{Experimento \expA, Matriz de confusão do \dataset \emph{Kyoto} Dez. 2015.}
  \label{tab:java-matrix}
  \begin{tabular}{l *{14}{|r} }
    Rótulos   &     - &       N &    1 &    2 &    3 &  4 &   5 &    6 &    7 &     8 &    9 &    10 &   11 &  12 \\\hline
    Classes  &       &         &      &      &      &    &     &      &      &       &      &       &      &     \\\hline
    \hline
    A        &  3\;774 &  438\;750 &  123 &  145 &  368 &  8 &  52 &  165 &    1 &  1\;046 &  161 &  2\;489 &   71 &  26 \\\hline
    N        &  8\;206 &  193\;030 &    0 &   79 &   44 &  0 &   0 &    0 &  229 &   181 &  154 &  4\;066 &  289 &   0 \\\hline
    \hline
    Associação &     - &       N &    A &    A &    A &  A &   A &    A &    N &     A &    A &     N &    N &   A \\\hline
    Hits ($tp$)     &     0 &  193\;030 &  123 &  145 &  368 &  8 &  52 &  165 &  229 &  1\;046 &  161 &  4\;066 &  289 &  26 
  \end{tabular}
\end{center}
}
\end{table}

Comparando as duas matrizes, a primeira diferença aparente é o índice do
primeiro rótulo novidade ($0$ ao invés de $1$), mas isso se deve apenas à decisão
arbitrária de íncide inicial de novidades.
% A sentença a seguir está bem longa, difícil de acompanhar. Fragmentar?
A primeira diferença notável que influi nas métricas de qualidade é a falta de 3
rótulos novidade, $12$ rótulos no experimento \expA ($[1,12]$) e $9$ no
experimento \expB ($[0,10]$ exceto $\{3,9\}$).
Também nota-se o número de exemplos desconhecidos,
$11\,980$ no experimento \expA e
$28\,567$ no experimento \expB e, o montante de exemplos incluídos nos rótulos
novidade, muito menor no experimento \expB.

\begin{table}[hbt]%{\linewidth}
  % {\small
  % \setlength\tabcolsep{0.5em}
  \begin{center}
  \caption{Experimento \expB, Matriz de confusão do \dataset \emph{Kyoto} Dez. 2015.}
  \label{tab:libc-matrix}
  \begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r}
    Rótulos &      - &       N &   0 &    1 &    2 &   4 &   5 &  6 &   7 &   8 &  10 \\\hline
    Classes  &        &         &     &      &      &     &     &    &     &     &     \\\hline
    \hline
    A        &  16\;086 &  429\;765 &  94 &  995 &  104 &   0 &  23 &  3 &  29 &  46 &  34 \\\hline
    N        &  12\;481 &  193\;642 &   3 &   94 &    0 &  47 &   0 &  0 &   0 &  11 &   0 \\\hline
    \hline
    Associação &      - &       N &   A &    A &    A &   N &   A &  A &   A &   A &   A \\\hline
    Hits ($tp$)     &      0 &  193\;642 &  94 &  995 &  104 &  47 &  23 &  3 &  29 &  46 &  34 
  \end{tabular}
  \end{center}
  % }
\end{table}

Estas três diferenças são atribuídas à divergência entre as definições de raio
discutidas na Seção \ref{sec:minas-og}, Equações \ref{eq:raio_paper} e
\ref{eq:raio_max}.
Esta divergência muda o comportamento do passo de classificação, resultando em
um conjunto diferente de desconhecidos e, por fim, mudando muito o resultado da
detecção de novidades.
Adicionalmente, como o parâmetro $f_{raio}$ (\texttt{radiusF}) da Equação
\ref{eq:raio_max} não existe na versão com raio definido como distância máxima
da Equação \ref{eq:raio_max}, o valor deste parâmetro foi escolhido
experimentalmente observando os resultados durante a implementação.

Além das matrizes de confusão, que dão uma visão detalhada porém limitada ao
último instante do fluxo, pode-se comparar as visualizações de fluxo onde as
métricas de qualidade são apresentadas para todos instantes do fluxo.
As Figuras \ref{fig:validation-java} e \ref{fig:validation-serial} ilustram os
fluxos de saída dos experimentos \expA e \expB respectivamente.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.75\linewidth]{experiments/revised-java-log.png}
  \caption{Experimento \expA, visualização de fluxo do \dataset \emph{Kyoto} Dez. 2015.}
  \label{fig:validation-java}
\end{figure}

As Figuras \ref{fig:validation-java} e \ref{fig:validation-serial} reforçam a
observação anterior de que mais rótulos novidade (linhas tracejadas verticais
com rótulo no topo) foram encontrados no experimento \expA do que as encontradas 
no experimento \expB.
Outro aspecto com relação a rótulos novidade, no experimento \expA eles surgem
mais ``cedo'' no fluxo, sendo a primeira marcação em $x=58\,967$ contra $x=94\,155$ no
experimento \expB.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.75\linewidth]{experiments/online-nd-log.png}
  \caption{Experimento \expB, visualização de fluxo do \dataset \emph{Kyoto} Dez. 2015.}
  \label{fig:validation-serial}
\end{figure}

O gráfico de visualização do fluxo tem no eixo horizontal (x, domínio) o índice
do exemplo $x$ e o eixo vertical (y, imagem) mostra o valor das métricas de qualidade
calculadas até aquele índice de exemplo $x$ no fluxo de saída capturado.
As linhas horizontais na visualização de fluxo mostram o progresso das métricas
de qualidade de classificação durante o fluxo e, ao final na esquerda, o valor
impresso junto e de mesma cor da linha é o valor final de cada métrica.
As métricas são: 
em laranja a taxa de desconhecidos (\texttt{unk}),
em verde a acurácia (\texttt{hit}) e
em azul o erro (\texttt{err}).
Estas métricas podem ser arranjadas em uma tripla-sumário
(\texttt{unk}, \texttt{hit}, \texttt{err})
com os valores em pontos percentuais para fácil comparação.

% Por último, o gráfico de visualização do fluxo mostra as métricas de qualidade
% resumida (\ emph {Acessos}, \ emph {Desconhecidos}, \ emph {Erros}) computada
% para cada exemplo no fluxo de saída capturado. Este resumo é calculado para cada
% exemplo, mas usa a linha \ emph {Atribuída} calculada anteriormente para avaliar
% \ emph {Acertos}; as outras medidas são derivadas conforme descrito antes. 

% Lastly, the stream visualization chart shows the summary quality measurement
% (\emph{Hits}, \emph{Unknowns}, \emph{Misses})
% computed for each example in the captured output stream.
% This summary is computed for each example, but it uses the \emph{Assigned} row
% computed previously to evaluate \emph{Hits}; the other measurements are derived as
% described before.
% The Horizontal axis (x, domain) plots the index of the example and the
% vertical axis (y, image) shows the measurement computed until that example index on the captured
% output stream.

Em conclusão das métricas de qualidade de classificação, os experimentos \expA e
\expB não são idênticos, pois não implementam a mesma definição para o raio,
porém são equivalentes em seus resultados.
Enquanto o experimento \expA tem tripla-sumário
($1.8\%,\: 30.6\%,\: 67.6\%$),
o experimento \expB piora marginalmente nas métricas com
($4.4\%,\: 29.8\%,\: 65.8\%$),
tendo mais desconhecidos, menor acurácia e menor erro.

Para as métricas de escalabilidade, os experimentos \expA e
\expB servem somente como base
para os próximos experimentos onde o paralelismo passa a ser utilizado.
Uma última nota quanto ao tempo de execução, mesmo não sendo paralelo, as
otimizações de memória, redução do uso de \emph{strings} e condição de parada do
algoritmo \emph{K-Means}, reduziram o tempo utilizado pela implementação de
referência de $2\;772s$ ($917s$ \emph{offline} e $1\;845s$ \emph{online}) para
$287s$ ($194s$ \emph{offline} e $93s$ \emph{online} no experimento \expB) na
nova implementação.

\subsection{Paralelismo e Distribuição}
\label{subsec:parallel-dist}

% For the measurements summary table, six measurements from two sources are displayed. Three
  % measures \emph{Hits}, \emph{Unknowns} and \emph{Misses} represented as ratio of
  % the captured output stream, extracted from the evaluation python program,
  % computed as follows:
  % \emph{Hits} (true positive rate) is the sum of the \emph{Hits} row in the
  % extended confusion matrix;
  % \emph{Unknowns} is the count of examples in the captured output stream marked
  % with the \emph{unknown} label (\emph{``-''});
  % \emph{Misses} is the count of all examples in the captured output stream marked
  % with a label distinct from the \emph{Assigned} original class and are not marked
  % as unknown.

  % Furthermore in the measurement summary table, \emph{Time}, \emph{System} and \emph{Elapsed}
  % represented in seconds, are extracted from \emph{GNU Time 1.9}.
  % \emph{Time} is the amount of CPU seconds expended in user-mode
  % (indicates time used doing CPU intensive computing, e.g., math);
  % \emph{System} is the amount of CPU seconds expended in kernel-mode
  % (for our case, it indicates time doing input or output);
  % \emph{Elapsed} is the real-world (wall clock) elapsed time and
  % indicates how long the program took to complete.
  % The lower the times, the better.
  % Our four main experiments are shown in Tab. \ref{tab:exper-summary}.

  % Lastly, the stream visualization chart shows the summary quality measurement
  % (\emph{Hits}, \emph{Unknowns}, \emph{Misses})
  % computed for each example in the captured output stream.
  % This summary is computed for each example, but it uses the \emph{Assigned} row
  % computed previously to evaluate \emph{Hits}; the other measurements are derived as
  % described before.
  % The Horizontal axis (x, domain) plots the index of the example and the
  % vertical axis (y, image) shows the measurement computed until that example index on the captured
  % output stream.

  % Adding to the stream visualization chart, novelty label markers are represented
  % as vertical lines indicating \emph{when} in the captured output stream a new
  % label first appeared.
  % Some of the novelty label markers include the label itself ($l \in \mathbb{N}$)
  % for reference (showing every label would turn this feature unreadable due
  % to overlapping).
  % Figure \ref{fig:visualization} shows complete stream visualization charts.

  % \begin{table*}[htb]
  % \caption{Confusion Matrixes and Qualitative measurements}
  % \label{tab:confusion-matrixes-ref-serial}

% \vspace{3ex}

Seguindo as comparações, para avaliar a escalabilidade do \mfog, foram
realizados dois experimentos que seguem o mesmo roteiro, o experimento \expC (1
nó e 4 núcleos) e o experimento \expD (3 nós e 12 núcleos).
As Tabelas \ref{tab:single-matrix} e \ref{tab:multi-matrix} mostram as matrizes
de confusão dos experimentos \expC e \expD respectivamente.

\begin{table}[hbt]
  \centering
  % \setlength\tabcolsep{0.5em}
  \caption{Experimento \expC, \mfog com 1 nó e 4 núcleos, Matriz de confusão do
  \dataset \emph{Kyoto} Dez. 2015.}
  \label{tab:single-matrix}
  \begin{tabular}{l|r|r|r|r|r|r|r}
    Rótulos &      - &       N &    0 &    1 &   2 &  3 &  4 \\\hline
    Classes  &        &         &      &      &     &    &    \\\hline
    \hline
    A        &  12\;282 &  433\;797 &  147 &  952 &   0 &  0 &  1 \\\hline
    N        &   3\;088 &  203\;019 &   40 &   99 &  27 &  5 &  0 \\\hline
    \hline
    Associação &      - &       N &    A &    A &   N &  N &  A \\\hline
    Hits ($tp$)     &      0 &  203\;019 &  147 &  952 &  27 &  5 &  1 
  \end{tabular}
\end{table}

A tripla-sumário do experimento \expC é ($2.4\%,\: 31.2\%,\: 66.4\%$), com menos
desconhecidos em relação ao experimento \expB ($4.4\%,\: 29.8\%,\: 65.8\%$).
A redução de desconhecidos é de $2\%$, sendo distribuída $1.4\%$ em acurácia e
$0.6\%$ em erro, representando melhora marginal em todas as métricas.
Além disso, este resultado fica mais próximo do experimento \expA ($1.8\%,\:
30.6\%,\: 67.6\%$).

% há algo estranho nesta frase, parece que falta uma vírgula ou conjunção...

Comparando as matrizes dos experimentos \expB e \expC, observa-se os
efeitos do paralelismo de classificadores e, mais importante, a execução
assíncrona da tarefa de detecção de novidade.
O impacto principal é a redução no número de rótulos novidade, de $9$ para $5$.
Comparando a visualização de fluxo, Figuras \ref{fig:validation-serial} e
\ref{fig:single-flow}, observa-se também que a aparição do primeiro padrão
novidade acontece mais ``tarde''; enquanto em \expB o rótulo novidade ``1'' é
observado em $x = 94\:155$, em \expC o mesmo rótulo é observado em $x =
172\:917$.

Esse comportamento é devido à detecção de novidade assíncrona, pois enquanto
essa tarefa é executada os classificadores continuam utilizando o modelo antigo.
Além disso, como já foi elencado na Seção \ref{sec:polices} item
\ref{reclassification}, os exemplos utilizados para formar o novo \mcluster
com rótulo novidade não são recolocados no fluxo de saída para nova análise.
Estas duas características do \mfog acarretam em um atraso significativo entre a
aparição de um padrão no fluxo de entrada e a aparição do rótulo correspondente
no fluxo de saída.
Em outras palavras, o fluxo avança com o modelo antigo e, mesmo após atualizado,
só gera uma saída com o rótulo novo quando (e se) o padrão aparece novamente.
Este é um resultado muito importante para compreender os problemas relacionados
à distribuição de um algoritmo deste gênero.

\begin{table}[hbt]
  \centering
  % \setlength\tabcolsep{0.5em}
  \caption{Experimento \expD, \mfog com 3 nós de 4 núcleos cada, Matriz de
  confusão do \dataset \emph{Kyoto} Dez. 2015.}
  \label{tab:multi-matrix}
  \begin{tabular}{l|r|r|r|r|r|r|r}
    Rótulos   &      - &       N &    0 &    1 &    2 &    3 &  4 \\\hline
    Classes   &        &         &      &      &      &      &    \\\hline
    \hline
    A      &  12\;378 &  433\;631 &  117 &  886 &    0 &  162 &  5 \\\hline
    N      &   3\;121 &  202\;916 &   40 &   96 &  105 &    0 &  0 \\\hline
    \hline
    Associação   &      - &       N &    A &    A &    N &    A &  A \\\hline
    Hits ($tp$)   &      0 &  202\;916 &  117 &  886 &  105 &  162 &  5 
  \end{tabular}
\end{table}

Avançando para o experimento \expD, a matriz de confusão na Tabela
\ref{tab:multi-matrix}, mostra pouca diferença quando comparado ao experimento
\expC, com o número de desconhecidos sofrendo a maior variação.

O mesmo é observado quando compara-se a visualização de fluxo, Figuras
\ref{fig:single-flow} e \ref{fig:multi-flow}, há pouca diferença e a tripla-sumário
($2.4\%,\: 31.2\%,\: 66.4\%$) é idêntica.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.75\linewidth]{experiments/tmi-base-log.png}
  \caption{Experimento \expC, \mfog com 1 nó e 4 núcleos, visualização de fluxo
  do \dataset \emph{Kyoto} Dez. 2015.}
  \label{fig:single-flow}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.75\linewidth]{experiments/tmi-n12-log.png}
  \caption{Experimento \expD, \mfog com 3 nós de 4 núcleos cada, visualização de
  fluxo do \dataset \emph{Kyoto} Dez. 2015.}
  \label{fig:multi-flow}
\end{figure}

Isto reforça a ideia de que o maior impacto nas métricas de qualidade de
classificação é a mudança de detecção de novidade assíncrona, pois mesmo com o
triplo de instâncias classificadoras, as métricas continuam idênticas.

Com a discussão das métricas de qualidade de classificação concluída, resta
abordar as métricas de escalabilidade que são muito mais simples em sua
definição e extração porém de muito interesse a este trabalho.

Essas métricas de escalabilidade extraídas dos experimentos são número de
núcleos de processamento utilizados, \emph{Tempo}, \emph{Sistema} e
\emph{Decorrido}, representados em segundos, e obtidas via \emph{GNU Time 1.9}
durante a execução do experimento em questão.
\emph{Tempo} é a quantidade de segundos de CPU gastos no modo de usuário
(indica o tempo usado em computação intensiva, por exemplo cálculos matemáticos).
\emph{Sistema} é a quantidade de segundos de CPU gastos no modo \emph{kernel} (para
nosso caso, indica o tempo de entrada ou saída).
\emph{Decorrido} é o tempo decorrido do mundo real (relógio de parede) e indica
quanto tempo o programa levou para ser concluído.
Quanto mais baixos os tempos, melhor.

Os quatro experimentos principais são mostrados na Tabela
\ref{tab:exper-summary}, relacionando as métricas de qualidade de classificação
da tripla-sumário (\texttt{unk}, \texttt{hit}, \texttt{err}) e as métricas de
escalabilidade.

Na Tabela \ref{tab:exper-summary}, a coluna \emph{Offline} representa os valores
de métricas de tempo de execução para a fase \emph{Offline} (treinamento) nos
experimentos utilizando o \mfog (\expB, \expC e \expD).
Esta distinção é necessária pois a implementação de referência do algoritmo
\minas executa as duas fases sem separação. Já o tempo de treinamento no \mfog é
mostrado na coluna \emph{Offline}.
Uma modificação da implementação de referência mostrou que dos $2\;772.07$
segundos listados na tabela, $917s$ são da fase \emph{offline} e $1\;845s$ da
fase \emph{online}.

\newcommand{\mr}[1]{\multirow{2}{*}{\texttt{#1}}}

\begin{table}[hbt]
  \centering
% \setlength\tabcolsep{0.35em}
\setlength\extrarowheight{2pt}
  \caption{Sumário das métricas extraídas dos experimentos principais.}
  \label{tab:exper-summary}
  \begin{tabular}{l|r|r|r|r|r}
  Experimento     & \expA         & \emph{Offline} & \expB     & \expC    & \expD    \\
  Métrica         &               &               &                 &                 &        \\\hline
  \mr{unk}        & $11980$       &               & $28567$         & $15370$     & $15499$     \\
                  & $0.018333$    &               & $0.043717$      & $0.023521$  & $0.023718$  \\\hline
  \mr{hit}        & $199708$      &               & $195017$        & $204151$    & $204191$    \\
                  & $0.305618$    &               & $0.298438$      & $0.312416$  & $0.312478$  \\\hline
  \mr{err}        & $441769$      &               & $429873$        & $433936$    & $433767$    \\
                  & $0.676049$    &               & $0.657843$      & $0.664061$  & $0.663802$  \\\hline
  Tempo     ($s$) & $2761.83$     & $194.12$      & $80.79000$      & $522.1000$  & $207.1400$  \\\hline
  Sistema   ($s$) & $7.15$        & $ 0.075$      & $11.51000$      & $ 47.7700$  & $157.6100$  \\\hline
  Decorrido ($s$) & $2772.07$     & $194.27$      & $93.03000$      & $145.0400$  & $ 95.3800$  \\\hline
  Latência  ($s$) & $4.24\cdot10^{-3}$  &       & $1.42\cdot10^{-4}$  & $2.22\cdot10^{-4}$  & $1.46\cdot10^{-4}\ $  \\\hline
  Processadores   & $1$           &  $1$          &  $1$            & $4$         & $12$        \\\hline
  \emph{Speedup}  &               &               &                 & $0.6414092$ & $0.9753617$  \\\hline
  Eficiência      &               &               &                 & $0.1603523$ & $0.0812801$  
  \end{tabular}
\end{table}

Além das métricas extraídas dos experimentos, as métricas de escalabilidade
calculadas a partir dos valores extraídos são a latência de eventos e
\emph{speedup}. % prático.
A latência média é calculada com o tempo decorrido dividido pelo o tamanho do
\dataset e pode ser vista na Tabela \ref{tab:exper-summary}.
O \emph{speedup} é calculado com a divisão do tempo decorrido na versão
sequencial divido pelo tempo utilizado pela versão paralela.
A eficiência é calculada com a divisão do tempo decorrido na versão sequencial
divido pelo produto do número de processadores utilizado e o tempo utilizado
pela versão paralela.

Observando as métricas de escalabilidade nota-se que o \mfog não fornece
\emph{speedup} e eficiência em relação à versão sequencial.
Isto indica que, apesar da premissa de independência de classificadores
paralelos, a comunicação entre os processos utilizando dois conjuntos de
instruções \mpi \emph{send} e \emph{receive} para cada exemplo não é eficiente
para o processamento de fluxo de dados.

\subsection{Experimentos Adicionais}

Experimentos adicionais foram realizados para melhor compreender o comportamento do \mfog
para número variado de processadores entre $1$ e $12$ utilizando de $1$ a $3$ nós.
Os resultados obtidos, ilustrados na Figura \ref{fig:speedup}, são limitados ao
nó raiz, e mostram um aumento do tempo \emph{Sistema} (operações em modo
\emph{kernel}).
Este aumento indica maior carga associada às operações de entrada e saída das
instruções \emph{send} e \emph{receive} reforçando a ideia apresentada na
Subseção \ref{subsec:parallel-dist}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.65\linewidth,page=1]{experiments/speedup-clean.pdf}
  \caption{Métricas de tempo para execuções do \mfog com variação no número de processadores.}
  \label{fig:speedup}
\end{figure}

Outros experimentos adicionais foram realizados para averiguar a latência para
cada exemplo do fluxo, mostrando o comportamento de cada implementação, o que é
ilustrado na Figura \ref{fig:lag}.
No entanto, é importante destacar que esta métrica não foi extraída dos
experimentos principais, sendo apenas ilustrativa dos diferentes comportamentos.

% não entendi essa questão de que os dados não foram obtidos de experimentos. Como os gerou?

\begin{figure}[h]
  \centering
  % \begin{minipage}{0.49\textwidth}
  %   \centering
  %   \includegraphics[width=1\linewidth,page=1]{experiments/speedup-clean.pdf}
  %   \caption{Métricas de tempo para execuções do \mfog com variação no número de processadores.}
  %   \label{fig:speedup}
  % \end{minipage}%
  % \hfill
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{experiments/lag-java.png}
    \caption{Implementação de referência.}
    \label{fig:lag-java}
  \end{subfigure}
  \hfill
  % \vspace{5mm}
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{experiments/lag-serial.png}
    \caption{Implementação sequencial.}
    \label{fig:lag-serial}
  \end{subfigure}
  % \vspace{5mm}
  % \hfill
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{experiments/lag-mfog.png}
    \caption{Implementação paralela.}
    \label{fig:lag-mfog}
  \end{subfigure}
  \caption{Visualização de Latência das implementações de referência, sequencial
  e paralela do algoritmo \minas.}
  \label{fig:lag}
\end{figure}
% \FloatBarrier

O primeiro comportamento é ilustrado na Figura \ref{fig:lag-java}, onde a execução
da tarefa de detecção de novidade gera picos de $50$ a $200$ segundos
na implementação de referência do algoritmo \minas.
Um comportamento semelhante é visto na Figura \ref{fig:lag-serial} onde ainda há
picos de latência, porém não tão intensos e frequentes na implementação sequencial
do algoritmo \minas utilizado a biblioteca do \mfog.
Esta diferença está relacionada com mecanismo de remoção de desconhecidos e
ausência do mecanismo de esquecimento de \mclusters menos utilizados no Modelo.
Já o comportamento visto na Figura \ref{fig:lag-mfog}, extraído do \mfog, mostra o efeito de
\emph{buffers} de comunicação entre diferentes processos onde o pico de latência
da detecção de novidade cai progressivamente conforme os buffers são esvaziados
já que o processo de detecção de novidade é assíncrono, porém ocupa a \emph{thread}
responsável pelo fluxo de saída do \mfog.

\section{Conclusão}
\label{sec:exp-conclusao}

Os experimentos executados e os resultados obtidos demonstram que a \acf{ND}
executada de maneira distribuída em ambiente de névoa é uma estratégia
válida para detecção de mudanças nos padrões de tráfego, sendo viável como parte
de um \acf{NIDS} para redes \iot.

No entanto para aplicação em uma situação real, são necessárias otimizações
desde o \dataset de treinamento e avaliação, passando pelo algoritmo de detecção
de novidade, parâmetros do algoritmo e estratégias de paralelismo e
distribuição.
