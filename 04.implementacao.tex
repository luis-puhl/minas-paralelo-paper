\chapter{Implementação e testes}
% cap 4: Implementação e testes
%     4.1. descrição da implementação
%         - offline, online, ND, Clustering
%         - observação de paralelização
%         - complexidade bigO (?)
%     4.2. cenário de teste 
%         - detecção de intrusão
%         - Arquitetura guilherme (dispositivos pequenos vs cloud)
%     4.3. Resultados de experimentos
%         - gráficos, tempos, tabelas...
%         - análises e comentários


\section{Descrição da Implementação}
% \section{Objetivos a serem alcançados}
% O que de fato vc irá fazer 

- offline, online, ND, Clustering

- observação/Considerações de paralelização

Notas sobre implementação Python/Kafka/Minas (não escala como esperado)

Dificuldade no processamento distribuido em Flink.

- complexidade bigO (?)

\section{Cenário de Teste}

Para testar e demonstrar essa implementação um cenário de aplicação é construido
onde seria vantajoso distribuir o processamento segundo o modelo \emph{fog}. Alguns
cenários de exemplo são
casos onde deve-se tomar ação caso uma classe ou anomalia seja detectada

- detecção de intrusão
- Arquitetura guilherme (dispositivos pequenos vs cloud)
\cite{Cassales2019a}
% Descrever a arquitetura IDS-IoT do paper do Guilherme

- BigFlow com dataset atual e maior
dataset kdd99
% dataset kyoto não está disponível http://www.takakura.com/Kyoto_data/

\section{Experimentos e Resultados}
    - gráficos, tempos, tabelas...
    - análises e comentários

Mostrar alguma implementação já feita e que esteja funcionando minimamente

Mostrar resultados mesmo que sejam bem simples e básicos,
apenas para demonstrar que vc domina o ambiente e as ferramentas e
que está apto a avançar no trabalho 

% discussão de 2020-02-01
passos feitos/a fazer
1. Entender Minas
2. Analisar/descrever dataset KDD
3. Notas sobre implementação Python/Kafka/Minas (não escala como esperado)
4. BigFlow (dataset mais novo, usa flink)
5. Plataforma Flink (processamento distribuído)
Proposta
6. Implementar minas em Scala/Flink
7. Testar com datasets KDD e BigFlow
8. Validar/Comparar métricas com seus trabalhos correspondentes
%/discussão

% Notas lendo Quali Casssales:
- Descrição do hardware utilizado pode conter:
    - Arch, OS, Kernel,
    - CPU (core, thread, freq),
    - RAM (total/free size, freq),
    - Disk (total/free size, seq RW, rand RW),
    - Net IO between nodes (direct crossover, switched, wireless, to cloud) (bandwidth, latency).
essas métricas permitem relacionar trade-offs para as questões de fog: Processar em node, edge ou cloud?

Provavelmente vou retirar o kafka da jogada em node/edge, deixando apenas em cloud.
